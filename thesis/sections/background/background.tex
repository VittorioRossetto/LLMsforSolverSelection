\documentclass[../../main]{subfiles}
\begin{document}

In this chapter, the main intention is to give the reader an initial knowledge base on all the theoretical concepts and all the components that had been utilized in the development of this research.

In the first section we will provide a description of constraint programming (CP) itself, starting from a general definition, delving deeper in the description of CP solvers, and then we are gonna provide a brief description of MiniZinc, a CP modelling language, in wich all the tested problems are coded.

In the second section we will provide an high level description of what large language models (LLMs) are and how they work, starting from the implementation of inference and decoding, passing to prompting techniques and prompt engineering, finally explaining the use of Application Programming Interfaces (APIs) as a communication mean.

\section{Constraint Programming}
Constraint programming (CP) is a software technology for declarative description and effective solving of large, particularly combinatorial, problems especially in areas of planning and scheduling~\cite{CPholygrail}.

A constraint can be thought of intuitively as a formalization of dependencies in physical worlds and their mathematical abstractions. A constraint is a logical relation among several unknowns (or variables), each taking a value in a given domain. The constraint thus restricts the possible values that variables can take; it represents partial information about the variables of interest. Constraints can also be heterogeneous, so they can bind unknowns from different domains, for example a length (number) with a word (string). The important feature of constraints is their declarative manner, i.e., they specify what relationship must hold without specifying a computational procedure to enforce that relationship~\cite{CPholygrail}.

Constraints arise naturally in most areas of human endeavor. They are the natural medium of expression for formalizing regularities that underlie the computational and (natural or designed) physical worlds and their mathematical abstractions. 

Constraint programming is the study of computational systems based on constraints. The idea of constraint programming is to solve problems by stating constraints (requirements) about the problem area and, consequently, finding a solution satisfying all the constraints.

As stated by E. C. Freuder thirty years ago,
\begin{displayquote}
``Constraint Programming represents one of the closest approaches computer science has yet made to the Holy Grail of programming: the user states the problem, the computer solves it.''~\cite{holygrail}.
\end{displayquote}

\subsection{CP Solvers}
In the courses of this research paper, we will often talk about ``Solvers''.
A CP solver is defined as a system or program that manipulates constraints to find solutions that satisfy specified conditions. It can utilize various approaches to enhance flexibility and customization within specific constraint domains, particularly finite domains.

% So, given that a CP model is a tuple $\langle X, D, C, O \rangle$ where $X$ is the set of variables we are trying to assign a value to, $D(x)$ is the domain associated with each variable $x \in X$, $C$ is the set of constraints that the variables must respect, and $O$ is an objective function, the goal of the solver is to assign a value for each variable $x \in X$ from $D(x)$ that satisfies all the constraints in $C$ and optimizes the objective function $O$~\cite{SeaPearl}.

So, given that a CP model can be defined as a tuple
\[
\langle X, D, C, O \rangle,
\]
where \(X\) is a finite set of decision variables, \(D(x)\) denotes the domain associated with each variable \(x \in X\), \(C\) is a set of constraints over subsets of \(X\), and \(O\) is an optional objective function. A solution is an assignment \(s : X \rightarrow \bigcup_{x \in X} D(x)\) such that \(s(x) \in D(x)\) for all \(x \in X\) and all constraints in \(C\) are satisfied~\cite{SeaPearl}.

This general formulation encompasses two main problem classes.

A ``Constraint Satisfaction Problem'' (CSP) is obtained when no objective function is defined. Formally, a CSP is the tuple
\(
\langle X, D, C \rangle,
\)
and the goal is to determine whether there exists at least one assignment satisfying all constraints, or to enumerate such assignments.

A ``Constraint Optimization Problem'' (COP) extends the CSP by introducing an objective function \(O : S \rightarrow \mathbb{R}\), where \(S\) is the set of feasible assignments. The goal is to find a feasible assignment \(s^*\) such that
\(
s^* = \arg\min_{s \in S} O(s) \quad \text{or} \quad s^* = \arg\max_{s \in S} O(s),
\)
depending on whether the problem is a minimization or maximization task.


\subsubsection{Portfolio Solvers}
Solving combinatorial search problems is hard, and there exist nowadays plenty of techniques and constraint solvers for performing this task. It has become clear that different solvers are better when solving different problem instances, even within the same problem class. It has also been shown that a single, arbitrarily efficient solver can be significantly outperformed by using a portfolio of possibly on-average slower solvers~\cite{PortfolioSolvers}.

Algorithm portfolios~\cite{AlgPortfolio} can be seen as instances of the more general Algorithm Selection problem~\cite{AlgSelProb} where, as reported in~\cite{AlgSelCSP}, the algorithm selection is performed case-by-case for each problem to solve. Within the context of constraint solving, a portfolio approach enables to combine a number $m > 1$ of different constituent solvers $s_1, \dots, s_m$ in order to create a globally better constraint solver, dubbed a portfolio solver. When a new, unseen problem $p$ comes, the portfolio solver tries to predict the best constituent solver(s) $s_{i_1}, \dots, s_{i_k}$ (with $1 \leq i_j \leq m$ for $j = 1, \dots, k$) for solving $p$ and then runs them on $p$. Properly selecting and scheduling the solvers is a crucial step for the performance of a portfolio solver, and it is usually performed by exploiting Machine Learning techniques based on features extracted from the problem $p$ to solve.

In the course of this research thesis, starting from the idea behind portfolio solvers, we will try to evaluate the performances of an agentic solver that uses pre-trained large language model as its agent to understand if this could be a viable solution to the algorithm selection problem~\cite{AlgSelProb}, following the new paradigm proposed in~\cite{fromPFStoAS}.

\subsection{MiniZinc}
MiniZinc is a simple but expressive CP modelling language which is suitable for modelling problems for a range of solvers and a reasonable compromise between many design possibilities.

Born from the necessity of a standard modelling language for constraint programming problems also making solver benchmarking simpler~\cite{MiniZinc}.

For these reasons all of the problems employed for testing in the course of this research paper were written using MiniZinc.

\subsubsection{Specifying a Problem}
A MiniZinc problem specification has two parts: (a) the model, which describes
the structure of a class of problems; and (b) the data, which specifies one particular problem within this class. The pairing of a model with a particular data set is a model instance (sometimes abbreviated to instance).

The model and data may be in separate files. Data files can only contain assignments to parameters declared in the model. A user specifies data files on the command line, rather than naming them in the model file, so that the model file is not tied to any particular data file~\cite{MiniZinc}.

\subsubsection{A MiniZinc Example}
Each MiniZinc model is a sequence of items, which may appear in any order.
Consider the MiniZinc model and example data for a restricted job shop scheduling problem in \Cref{fig:minizincModelEx} and \Cref{fig:minizincDataEx}.

Line 0 is a comment, introduced by the ``\%'' character.

Lines 1-5 are ``variable declaration items''. Line 1 declares \texttt{size} to be an integer parameter, i.e. a variable that is fixed in the model. Line 20 (in the data file) is an ``assignment item'' that defines the value of \texttt{size} for this instance. Variable declaration items can include assignments, as in line 3. Line 4 declares \texttt{s} to be a 2D array of ``decision variables''. Line 5 is an integer variable with a restricted range. Decision variables are distinguished by the \texttt{var} prefix.

Lines 7-8 show a user-defined ``predicate item'', \texttt{no\_overlap}, which constrains two tasks given by start time and duration so that they do not overlap in time.

Lines 10-17 show a ``constraint item''. It uses the built-in \texttt{forall} to loop over each job, and ensure that: (line 12) the tasks are in order; (line 13) they finish before end; and (lines 14-16) that no two tasks in the same column overlap in time. Multiple constraint items are allowed, they are implicitly conjoined.

Line 19 shows a \texttt{solve item}. Every model must include exactly one solve
item. Here we are interested in minimizing the end time. We can also maximize
a variable or just look for any solution (\texttt{solve satisfy}).

There is one kind of MiniZinc item not shown by this example: ``include items''.
They facilitate the creation of multi-file models and the use of library files~\cite{MiniZinc}.

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.75\linewidth]{minizincModelEx.png}
    \caption{MiniZinc model (\texttt{jobshop.mzn}) for the job shop problem(the portrayed example was taken from ~\cite{MiniZinc}).}
    \label{fig:minizincModelEx}
\end{figure}
\begin{figure}[ht]
    \centering
    \includegraphics[width=0.75\linewidth]{minizincDataEx.png}
    \caption{MiniZinc data (\texttt{jobshop2x2.dzn}) for the job shop problem (the portrayed example was taken from ~\cite{MiniZinc}).}
    \label{fig:minizincDataEx}
\end{figure}


\subsubsection{MiniZinc Challenge}
Comparing constraint programming systems is fraught with difficulty and in reality an impossible task. The reason is that there are so many components to a modern CP system, only some of which are implemented by some systems. To claim that one CP system is ``better'' than another is a bold claim, since there is almost certainly some problem for which the ``worse'' system allows a stronger model, or a better search, and performs better.

MiniZinc makes a good attempt to handle the most obvious obstacle: there are hundreds of potential global constraints, most handled by few or no systems. 
A standard input language, gives us the capability to compare different solvers.
Hence, every year since 2008 the MiniZinc Challenge has been comparing different solvers that support MiniZinc~\cite{PhilMznChallenge}.

The aim of the challenge is to compare various constraint solving technology on the same problems sets. The focus is on finite domain propagation solvers. An auxiliary aim is to build up a library of interesting problem models, which can be used to compare solvers and solving technologies.

Challenge participants provide a FlatZinc or MiniZinc solver and global constraint definitions specialized for their solver. Each solver is run on 100 MiniZinc model instances. For FlatZinc solvers, the minizinc compiler runs on the MiniZinc model and instance using the provided global constraint definitions to create a FlatZinc file. The resultant FlatZinc file is then given as input to the provided FlatZinc solver. For MiniZinc solvers, the MiniZinc model and data are input to the provided solver. Points are awarded for solving problems, speed of solution, and goodness of solutions (for optimization problems)~\cite{PhilMznChallenge}.

However, the MiniZinc challenge scoring system is not actually utilized in this specific research.

\section{Large Language Models}
\label{sec:LLM}
Large Language Models (LLMs) are neural network models trained to process and generate natural language by learning statistical patterns over large text corpora.

LLMs are the culmination of decades of progress in natural language processing (NLP) and machine learning research, and their development is largely responsible for the explosion of artificial intelligence advancements across the late 2010s and 2020s. Popular LLMs have become household names, bringing generative AI to the forefront of the public interest. LLMs are also used widely in enterprises, with organizations investing heavily across numerous business functions and use cases~\cite{LLMsIBM}.

LLMs are built on a type of neural network architecture called a transformer~\cite{TransformerArchitecture}, which employs self-attention mechanisms to model dependencies among tokens in a sequence. Formally, given an input sequence \(x_1, \dots, x_n\), the model estimates the conditional distribution
\[
P(x_{n+1} \mid x_1, \dots, x_n),
\]
and text generation proceeds autoregressively by repeatedly sampling from this distribution.

Training is typically divided into a large-scale pretraining phase followed by alignment stages. During pretraining, the model learns general linguistic and semantic representations through self-supervised objectives. Alignment techniques, such as supervised fine-tuning and reinforcement learning from feedback, adapt the model to follow instructions, respect constraints, and produce outputs that better match user expectations~\cite{LLMsIBM}.

To better explain the concept, we can say Large Language Models (LLMs) are, at their core, autoregressive statistical models that generate text by iteratively predicting the most probable subsequent token in a sequence, based on patterns learned from their training data.

\subsection{Inference and Decoding}

At inference time, the model produces logits \(l_k\) over the vocabulary, which are transformed into probabilities using a softmax function~\cite{InfeerenceTrainingLLMs}. Decoding strategies determine how the next token is selected from this distribution.

Modern LLMs typically generate text in a left-to-right, token-by-token fashion. For each prefix, the model computes a probability distribution of the next token over a fixed vocabulary. A decoding method defines how the generated token sequence is derived from these probability estimations. Deterministic approaches, select the most probable token at each step, while stochastic approaches introduce controlled randomness~\cite{LLMDecoding}.

Some notable deterministic approaches are: ``Greedy Search'', which is limited to selecting the token with highest probability at each time step, or ``Beam Search''~\cite{BeamSearch}, which maintains a beam of the $k$ most probable sequences at each time step, where the hyperparameter $k$ is referred to as the beam width.

Some notable stochastic methods are: Temperature Sampling samples tokens from the estimated next-token distributions. The skewness of distributions can be controlled using a temperature hyperparameter $\tau$, or Top-p Sampling, which only considers the minimal set of most probable tokens that cover a specified percentage p of the distribution.

A central practical constraint is the context window, which limits the total number of tokens that can be processed jointly as input and output. This constraint directly influences prompt design, the amount of contextual information that can be provided, and the feasibility of maintaining conversational state.

\subsection{Prompting and Interaction}

LLMs are typically controlled through prompting, where task instructions and contextual data are encoded in the input. 

Prompt engineering has emerged as an indispensable technique for extending the capabilities of large language models (LLMs) and vision-language models (VLMs). This approach leverages task-specific instructions, known as prompts, to enhance model efficacy without modifying the core model parameters. Rather than updating the model parameters, prompts allow seamless integration of pre-trained models into downstream tasks by eliciting desired model behaviors solely based on the given prompt. 

Prompts can be natural language instructions that provide context to guide the model or learned vector representations that activate relevant knowledge.
This rapidly growing field has enabled success across various applications, from question-answering to common sense reasoning~\cite{prompting}. 

\begin{figure}[ht]
    \centering
    \includegraphics[width=0.75\linewidth]{promptEngineering.png}
    \caption{Visual breakdown of prompt engineering components: LLMs trained on extensive data, instruction and context as pivotal elements shaping the prompt, and a user input interface (image was taken from ~\cite{prompting}).}
    \label{fig:promptEng}
\end{figure}

Some notable prompt engineering techniques are: ``Zero-Shot Prompting'' which offers a paradigm shift in leveraging large LLMs. This technique removes the need for extensive training data, instead relying on carefully crafted prompts that guide the model toward novel tasks, or ``Few-Shot Prompting'' which provides models with a few input-output examples to induce an understanding of a given task, unlike zero-shot prompting, where no examples are supplied~\cite{ZeroFewShot}.

Interaction may occur in a single-request mode, in which each task is processed independently, or in a multi-turn mode, where previous exchanges remain within the context window.

Prompt structure plays a significant role in model performance, particularly in technical tasks involving structured inputs, strict output formats, or long problem descriptions. The representation of information affects both the interpretability of the prompt and the effective use of the context window.

\subsection{Application Programming Interfaces}

In practical settings, LLMs are accessed through Application Programming Interfaces (APIs). An application programming interface, or API, enables commercial, military or private entities to make the data and functionality of their applications or systems available to external third-party developers, commercial partners, and internal departments within their own organizations. The usage of a defined interface enables services and products to interact with one another and benefit from each other's information and features. This interface is manipulated and programmed by developers to interact with other software, services or systems; they are not required to understand how a specific API is developed, and neither are the software's end-users. In short, an API is a contract between pieces of applications serving the main software once integrated into the source code of the main application~\cite{APIS}.

An LLM API provides a standardized mechanism for submitting input messages and receiving model outputs, together with configurable inference parameters such as temperature. API-based access introduces operational constraints, including limits on the number of requests or tokens processed within a given time interval, as well as maximum context sizes per interaction. But enables the use of complex LLMs without the need of high computational power. 

\subsection{Relevance to Solver Selection}
In this research, the aim is to test the potential of LLMs when used for solver selection. Where the prompt is engineered in order to help the LLM evaluate all the characteristics of a problem, to make a decision that is as functional as possible. 

When applied to solver selection, an LLM functions as a decision component that maps problem representations to solver choices. Its performance depends on both theoretical aspects, such as its ability to model complex input-output relationships, and practical factors, including prompt formulation, context management, and API-level parameters.


\end{document}