\documentclass[../../main]{subfiles}
\begin{document}

This thesis presents a systematic investigation of the use of Large Language Models (LLMs) ~\cite{LLMsIBM} within the domain of Constraint Programming (CP)~\cite{CPholygrail}, more specifically on the task of algorithm selection~\cite{AlgSelProb}, referred to as ``solver selection'' in the case of NP-complete problems. The objective is to assess whether general-purpose language models can effectively support or enhance decision processes that have traditionally relied on supervised learning.

Algorithm selection, aims to identify the most suitable algorithm for solving a specific problem prior to execution.  this issue has been prevailing in many domains, as no single algorithm can perform best on all problem instances.
Traditional algorithm selection and portfolio construction methods typically treat the problem as a classification or regression task~\cite{algSelRanking}.

LLMs are neural network architectures trained on large-scale text corpora to model statistical regularities in natural language. They represent the outcome of sustained advances in natural language processing and machine learning, and have recently demonstrated strong performance across a wide range of reasoning and generation tasks. Despite their broad adoption in general-purpose applications, their role in specialized technical domains such as CP, and specifically in automated solver selection, remains unexplored.

CP is a declarative paradigm for solving combinatorial problems, particularly those arising in planning, scheduling, and resource allocation~\cite{CPholygrail}. Problems are modeled in terms of variables, domains, and constraints, and are processed by solvers, i.e., software systems that search for assignments satisfying the constraints and, in optimization settings, improving a given objective function. Different solvers rely on distinct underlying technologies and heuristics, leading to performance variability across problem classes. Selecting an appropriate solver for a given instance is therefore a central challenge~\cite{evaluationMetaSolvers}.

The research presented in this thesis investigates the problem of algorithm selection, by using LLMs as decision-making components with a portfolio of solvers. This idea is inspired by~\cite{fromPFStoAS}, and takes inspiration from portfolio-based approaches, where multiple solvers are available and a central strategy determines which ones to execute for a given instance. Traditional portfolio methods rely on complex, supervised learning algorithms. In contrast, this work explores whether general-purpose LLMs, given suitable contextual information, can approximate or surpass these approaches without task-specific retraining.

After selecting a benchmark set of CP problems, specifically those used in the 2025 MiniZinc Challenge~\cite{PhilMznChallenge,MznResults25}, we identified a collection of general-purpose LLMs for evaluation. We then conducted iterative experiments to assess whether these models could outperform existing single solvers, systematically testing different prompt configurations and progressively enriching the contextual information provided. 

Initial results highlighted the limitations of LLMs for this task, yielding only marginal improvements over traditional solvers. To address these limitations, we incorporated structured problem representations using a feature extraction tool, \texttt{mzn2feat}~\cite{mzn2feat}, which produced the highest observed performance, even though by a minimal margin. Building on these insights, we also developed a tool to translate problem code into natural language descriptions, fzn2nl~\cite{fzn2nl}, on which we conducted further testing.

The structure of the thesis is as follows. Chapter~1 provides the technical background required for the remainder of the work. Chapter~2 describes the experimental methodology, evaluation metrics, and design choices underlying the study. Chapter~3 presents the core experimental results, beginning with baseline tests based on minimal problem representations, and progressively enriching the context with textual descriptions, structured features extracted from problem instances, and finally the implementation of temperature tuning. Chapter~4 introduces a complementary tool developed during this research, \texttt{fzn2nl}, which translates FlatZinc models into natural language descriptions, and finally we tested LLM performance when operating directly on such generated representations.

\end{document}