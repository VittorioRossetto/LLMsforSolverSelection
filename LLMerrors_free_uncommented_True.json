[
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "carpet-cutting",
    "instance": "cc_rnd_4_4.json",
    "error": "Server disconnected without sending a response.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "carpet-cutting",
    "instance": "cc_rnd_4_4.json",
    "error": "Server disconnected without sending a response."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 1.557641724s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '1s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 57.541613497s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '57s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 52.541795421s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '52s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 44.586409684s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '44s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 33.494407744s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '33s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 14.350693075s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 38.98745875s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '38s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 34.777402803s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '34s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 31.74621826s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '31s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 28.50517642s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 25.186905667s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '25s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 22.11995481s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '22s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 17.98364913s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 19.058178586s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '19s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 10.452242364s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '10s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 58.587962025s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '58s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 51.22539898s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '51s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "Server disconnected without sending a response.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "Server disconnected without sending a response."
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 16.708010452s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '16s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 12.830189351s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 6.271771455s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '6s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 4.493971596s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '4s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 59.287713974s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '59s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 47.916586292s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '47s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 28.038573885s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 55.871995556s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '55s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 52.843967109s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '52s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 52.427198106s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '52s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 49.536092927s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '49s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 49.115014908s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '49s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 46.301993295s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 44.761812651s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '44s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 42.650846422s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 41.337396222s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '41s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 38.51393338s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '38s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 34.767406208s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '34s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 33.306131692s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '33s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 28.279534867s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '28s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 27.014122945s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 23.741405657s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '23s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 21.804621268s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '21s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 19.325087885s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '19s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 17.423381241s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '17s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 14.588085506s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '14s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 12.816921913s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash', 'location': 'global'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '12s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 9.867658707s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '9s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 8.451386903s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '8s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 5.02566279s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '5s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 3.529909566s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '3s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 59.941736879s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '59s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 58.795461068s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '58s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 55.156129594s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'model': 'gemini-2.5-flash-lite', 'location': 'global'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '55s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 53.703967693s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '53s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 42.232251376s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '42s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 39.929010133s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '39s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 35.592680323s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '35s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 34.593228222s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '34s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 27.367094391s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '27s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \\n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_input_token_count, limit: 250000\\nPlease retry in 20.725515314s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_input_token_count', 'quotaId': 'GenerateContentInputTokensPerModelPerMinute-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash'}, 'quotaValue': '250000'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '20s'}]}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 0
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11869, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 2161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k6tdj201exjra3mspenq6dxe` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11526, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}",
    "size_error": false,
    "rate_error": true,
    "allowed_script_tokens": 161
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 2161
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_8_h16_r0.05_s0.5_3.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6377
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_8_h16_r0.05_s0.5_3.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_3_h39_r0.05_s0.5_0.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6479
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "cgt",
    "instance": "cgt_3_h39_r0.05_s0.5_0.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "EchoSched",
    "instance": "15-15-0-1_3.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "EchoSched",
    "instance": "15-15-0-1_3.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "EchoSched",
    "instance": "12-12-0-1_7.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "EchoSched",
    "instance": "12-12-0-1_7.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "EchoSched",
    "instance": "13-14-0-2_6.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "EchoSched",
    "instance": "13-14-0-2_6.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "EchoSched",
    "instance": "14-10-0-2_1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "EchoSched",
    "instance": "14-10-0-2_1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u15g5pref1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u15g5pref1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u15g1pref2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u15g1pref2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u15g3pref0.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "groupsplitter",
    "instance": "u15g3pref0.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "gt-sort",
    "instance": "n9_ub10_50.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "gt-sort",
    "instance": "n9_ub10_50.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "gt-sort",
    "instance": "n13_ub20_50.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "gt-sort",
    "instance": "n13_ub20_50.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "gt-sort",
    "instance": "n7_ub20_75.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "gt-sort",
    "instance": "n7_ub20_75.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "gt-sort",
    "instance": "n9_ub10_75.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "gt-sort",
    "instance": "n9_ub10_75.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "gt-sort",
    "instance": "n9_ub30_35.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "gt-sort",
    "instance": "n9_ub30_35.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "hitori",
    "instance": "h11-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "hitori",
    "instance": "h11-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "hitori",
    "instance": "h5-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "hitori",
    "instance": "h5-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "hitori",
    "instance": "h15-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "hitori",
    "instance": "h15-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "hitori",
    "instance": "h20-2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "hitori",
    "instance": "h20-2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "hitori",
    "instance": "h14-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "hitori",
    "instance": "h14-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-kletzander",
    "instance": "test05.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-kletzander",
    "instance": "test05.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-kletzander",
    "instance": "test03.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-kletzander",
    "instance": "test03.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-kletzander",
    "instance": "i09.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-kletzander",
    "instance": "i09.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-kletzander",
    "instance": "i02.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-kletzander",
    "instance": "i02.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-kletzander",
    "instance": "i07.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-kletzander",
    "instance": "i07.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-marte",
    "instance": "i14.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-marte",
    "instance": "i14.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-marte",
    "instance": "i06.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-marte",
    "instance": "i06.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-marte",
    "instance": "i01.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-marte",
    "instance": "i01.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "EchoSched",
    "instance": "14-10-0-2_3.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "EchoSched",
    "instance": "14-10-0-2_3.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-marte",
    "instance": "i11.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-marte",
    "instance": "i11.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-marte",
    "instance": "i03.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "ihtc-2024-marte",
    "instance": "i03.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "is",
    "instance": "BnMUR3YMRk.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "is",
    "instance": "BnMUR3YMRk.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "is",
    "instance": "avdoaYnfXq.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "is",
    "instance": "avdoaYnfXq.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "is",
    "instance": "1vERFuvviS.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "is",
    "instance": "1vERFuvviS.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "is",
    "instance": "9aGFgDaHX7.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "is",
    "instance": "9aGFgDaHX7.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "is",
    "instance": "vWQp9idqMs.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "is",
    "instance": "vWQp9idqMs.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "mondoku",
    "instance": "12-12-8.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "mondoku",
    "instance": "12-12-8.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "mondoku",
    "instance": "20-18-9.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "mondoku",
    "instance": "20-18-9.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "mondoku",
    "instance": "14-14-8.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "mondoku",
    "instance": "14-14-8.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "mondoku",
    "instance": "8-8-4.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "mondoku",
    "instance": "8-8-4.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "mondoku",
    "instance": "10-10-6.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "mondoku",
    "instance": "10-10-6.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "products-and-shelves",
    "instance": "ps-25-03.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "products-and-shelves",
    "instance": "ps-25-03.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "products-and-shelves",
    "instance": "ps-25-01.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "products-and-shelves",
    "instance": "ps-25-01.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "products-and-shelves",
    "instance": "ps-50-06.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "products-and-shelves",
    "instance": "ps-50-06.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "products-and-shelves",
    "instance": "ps-50-09.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "products-and-shelves",
    "instance": "ps-50-09.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "products-and-shelves",
    "instance": "toy.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "products-and-shelves",
    "instance": "toy.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.19aa.usingEref_self.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.19aa.usingEref_self.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "proteindesign12",
    "instance": "2TRX.11p.8aa.usingEref_self_x.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "proteindesign12",
    "instance": "2TRX.11p.8aa.usingEref_self_x.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.9aa.usingEref_self_x.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.9aa.usingEref_self_x.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.19aa.usingEref_self.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.19aa.usingEref_self.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.9aa.usingEref_self.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.9aa.usingEref_self.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_3m_3.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_3m_3.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2w_2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2w_2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_5d_1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_5d_1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2m_2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2m_2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_1m_2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_1m_2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l12_c6_n12.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l12_c6_n12.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "stripboard",
    "instance": "stripboard_w15_h10_l12_c6_n12.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "stripboard",
    "instance": "stripboard_w15_h10_l12_c6_n12.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l7_c6_n24.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l7_c6_n24.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "stripboard",
    "instance": "stripboard_w10_h10_l12_c4_n24.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "stripboard",
    "instance": "stripboard_w10_h10_l12_c4_n24.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l4_c4_n24.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l4_c4_n24.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tower",
    "instance": "tower_070_070_30_100-02.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tower",
    "instance": "tower_070_070_30_100-02.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tower",
    "instance": "tower_070_070_15_070-08.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tower",
    "instance": "tower_070_070_15_070-08.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tower",
    "instance": "tower_070_070_15_070-02.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tower",
    "instance": "tower_070_070_15_070-02.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tower",
    "instance": "tower_500_500_50_300-05.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tower",
    "instance": "tower_500_500_50_300-05.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tower",
    "instance": "tower_050_050_10_050-03.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tower",
    "instance": "tower_050_050_10_050-03.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tsptw",
    "instance": "n20w140.005.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tsptw",
    "instance": "n20w140.005.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tsptw",
    "instance": "n20w180.004.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tsptw",
    "instance": "n20w180.004.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tsptw",
    "instance": "n100w120.003.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tsptw",
    "instance": "n100w120.003.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tsptw",
    "instance": "n80w180.003.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tsptw",
    "instance": "n80w180.003.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tsptw",
    "instance": "n20w160.001.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "tsptw",
    "instance": "n20w160.001.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "work-task-variation",
    "instance": "generated-seed-10-length-12-open-10-workers-12-block-5.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "work-task-variation",
    "instance": "generated-seed-10-length-12-open-10-workers-12-block-5.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "work-task-variation",
    "instance": "generated-seed-1-length-16-open-14-workers-12-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "work-task-variation",
    "instance": "generated-seed-1-length-16-open-14-workers-12-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "work-task-variation",
    "instance": "generated-seed-4-length-14-open-12-workers-12-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "work-task-variation",
    "instance": "generated-seed-4-length-14-open-12-workers-12-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "work-task-variation",
    "instance": "generated-seed-8-length-12-open-10-workers-10-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "work-task-variation",
    "instance": "generated-seed-8-length-12-open-10-workers-10-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "work-task-variation",
    "instance": "generated-seed-3-length-10-open-8-workers-12-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash-lite",
    "problem": "work-task-variation",
    "instance": "generated-seed-3-length-10-open-8-workers-12-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "fbd1",
    "instance": "FBDk04.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "fbd1",
    "instance": "FBDk04.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "fbd1",
    "instance": "FBDk06.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "fbd1",
    "instance": "FBDk06.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "fbd1",
    "instance": "FBDk08.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "fbd1",
    "instance": "FBDk08.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "fbd1",
    "instance": "FBDk07.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "fbd1",
    "instance": "FBDk07.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u15g5pref1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u15g5pref1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u15g1pref2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u15g1pref2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u15g3pref0.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "groupsplitter",
    "instance": "u15g3pref0.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "gt-sort",
    "instance": "n9_ub10_50.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "gt-sort",
    "instance": "n9_ub10_50.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "gt-sort",
    "instance": "n13_ub20_50.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "gt-sort",
    "instance": "n13_ub20_50.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "gt-sort",
    "instance": "n7_ub20_75.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "gt-sort",
    "instance": "n7_ub20_75.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "gt-sort",
    "instance": "n9_ub10_75.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "gt-sort",
    "instance": "n9_ub10_75.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "gt-sort",
    "instance": "n9_ub30_35.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "gt-sort",
    "instance": "n9_ub30_35.0_BEST.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "hitori",
    "instance": "h11-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "hitori",
    "instance": "h11-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "hitori",
    "instance": "h5-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "hitori",
    "instance": "h5-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "hitori",
    "instance": "h15-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "hitori",
    "instance": "h15-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "hitori",
    "instance": "h20-2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "hitori",
    "instance": "h20-2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "hitori",
    "instance": "h14-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "hitori",
    "instance": "h14-1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-kletzander",
    "instance": "test05.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-kletzander",
    "instance": "test05.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-kletzander",
    "instance": "test03.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-kletzander",
    "instance": "test03.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-kletzander",
    "instance": "i09.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-kletzander",
    "instance": "i09.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-kletzander",
    "instance": "i02.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-kletzander",
    "instance": "i02.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-kletzander",
    "instance": "i07.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-kletzander",
    "instance": "i07.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-marte",
    "instance": "i14.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-marte",
    "instance": "i14.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-marte",
    "instance": "i06.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-marte",
    "instance": "i06.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-marte",
    "instance": "i01.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-marte",
    "instance": "i01.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-marte",
    "instance": "i11.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-marte",
    "instance": "i11.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-marte",
    "instance": "i03.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "ihtc-2024-marte",
    "instance": "i03.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "is",
    "instance": "BnMUR3YMRk.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "is",
    "instance": "BnMUR3YMRk.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "is",
    "instance": "avdoaYnfXq.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "is",
    "instance": "avdoaYnfXq.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "is",
    "instance": "1vERFuvviS.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "is",
    "instance": "1vERFuvviS.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "is",
    "instance": "9aGFgDaHX7.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "is",
    "instance": "9aGFgDaHX7.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "is",
    "instance": "vWQp9idqMs.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "is",
    "instance": "vWQp9idqMs.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "mondoku",
    "instance": "12-12-8.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "mondoku",
    "instance": "12-12-8.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "mondoku",
    "instance": "20-18-9.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "mondoku",
    "instance": "20-18-9.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "mondoku",
    "instance": "14-14-8.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "mondoku",
    "instance": "14-14-8.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "mondoku",
    "instance": "8-8-4.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "mondoku",
    "instance": "8-8-4.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "mondoku",
    "instance": "10-10-6.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "mondoku",
    "instance": "10-10-6.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "products-and-shelves",
    "instance": "ps-25-03.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "products-and-shelves",
    "instance": "ps-25-03.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "products-and-shelves",
    "instance": "ps-25-01.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "products-and-shelves",
    "instance": "ps-25-01.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "products-and-shelves",
    "instance": "ps-50-06.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "products-and-shelves",
    "instance": "ps-50-06.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "products-and-shelves",
    "instance": "ps-50-09.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "products-and-shelves",
    "instance": "ps-50-09.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "products-and-shelves",
    "instance": "toy.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "products-and-shelves",
    "instance": "toy.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "fbd1",
    "instance": "FBDk09.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "fbd1",
    "instance": "FBDk09.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.19aa.usingEref_self.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.19aa.usingEref_self.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "proteindesign12",
    "instance": "2TRX.11p.8aa.usingEref_self_x.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "proteindesign12",
    "instance": "2TRX.11p.8aa.usingEref_self_x.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.9aa.usingEref_self_x.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.9aa.usingEref_self_x.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.19aa.usingEref_self.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.19aa.usingEref_self.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.9aa.usingEref_self.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.9aa.usingEref_self.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_3m_3.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_3m_3.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2w_2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2w_2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_5d_1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_5d_1.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2m_2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2m_2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_1m_2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_1m_2.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l12_c6_n12.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l12_c6_n12.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "stripboard",
    "instance": "stripboard_w15_h10_l12_c6_n12.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "stripboard",
    "instance": "stripboard_w15_h10_l12_c6_n12.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l7_c6_n24.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l7_c6_n24.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "stripboard",
    "instance": "stripboard_w10_h10_l12_c4_n24.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "stripboard",
    "instance": "stripboard_w10_h10_l12_c4_n24.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l4_c4_n24.json",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l4_c4_n24.json",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tower",
    "instance": "tower_070_070_30_100-02.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tower",
    "instance": "tower_070_070_30_100-02.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tower",
    "instance": "tower_070_070_15_070-08.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tower",
    "instance": "tower_070_070_15_070-08.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tower",
    "instance": "tower_070_070_15_070-02.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tower",
    "instance": "tower_070_070_15_070-02.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tower",
    "instance": "tower_500_500_50_300-05.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tower",
    "instance": "tower_500_500_50_300-05.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tower",
    "instance": "tower_050_050_10_050-03.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tower",
    "instance": "tower_050_050_10_050-03.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tsptw",
    "instance": "n20w140.005.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tsptw",
    "instance": "n20w140.005.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tsptw",
    "instance": "n20w180.004.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tsptw",
    "instance": "n20w180.004.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tsptw",
    "instance": "n100w120.003.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tsptw",
    "instance": "n100w120.003.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tsptw",
    "instance": "n80w180.003.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tsptw",
    "instance": "n80w180.003.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tsptw",
    "instance": "n20w160.001.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "tsptw",
    "instance": "n20w160.001.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "work-task-variation",
    "instance": "generated-seed-10-length-12-open-10-workers-12-block-5.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "work-task-variation",
    "instance": "generated-seed-10-length-12-open-10-workers-12-block-5.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "work-task-variation",
    "instance": "generated-seed-1-length-16-open-14-workers-12-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "work-task-variation",
    "instance": "generated-seed-1-length-16-open-14-workers-12-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "work-task-variation",
    "instance": "generated-seed-4-length-14-open-12-workers-12-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "work-task-variation",
    "instance": "generated-seed-4-length-14-open-12-workers-12-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "work-task-variation",
    "instance": "generated-seed-8-length-12-open-10-workers-10-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "work-task-variation",
    "instance": "generated-seed-8-length-12-open-10-workers-10-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "work-task-variation",
    "instance": "generated-seed-3-length-10-open-8-workers-12-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 199795
  },
  {
    "when": "task_result",
    "provider": "gemini",
    "model": "gemini-2.5-flash",
    "problem": "work-task-variation",
    "instance": "generated-seed-3-length-10-open-8-workers-12-block-15.dzn",
    "error": "[Errno -3] Temporary failure in name resolution"
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "groupsplitter",
    "instance": "u15g5pref1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "groupsplitter",
    "instance": "u15g5pref1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "groupsplitter",
    "instance": "u15g1pref2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "groupsplitter",
    "instance": "u15g1pref2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "groupsplitter",
    "instance": "u15g3pref0.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "groupsplitter",
    "instance": "u15g3pref0.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "gt-sort",
    "instance": "n9_ub10_50.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "gt-sort",
    "instance": "n9_ub10_50.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "gt-sort",
    "instance": "n13_ub20_50.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "gt-sort",
    "instance": "n13_ub20_50.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "gt-sort",
    "instance": "n7_ub20_75.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "gt-sort",
    "instance": "n7_ub20_75.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "gt-sort",
    "instance": "n9_ub10_75.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "gt-sort",
    "instance": "n9_ub10_75.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "gt-sort",
    "instance": "n9_ub30_35.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "gt-sort",
    "instance": "n9_ub30_35.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 2161
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "hitori",
    "instance": "h11-1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "hitori",
    "instance": "h11-1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_8_h16_r0.05_s0.5_3.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6377
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_8_h16_r0.05_s0.5_3.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "hitori",
    "instance": "h5-1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "hitori",
    "instance": "h5-1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_3_h39_r0.05_s0.5_0.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6479
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "cgt",
    "instance": "cgt_3_h39_r0.05_s0.5_0.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "hitori",
    "instance": "h15-1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "hitori",
    "instance": "h15-1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "EchoSched",
    "instance": "15-15-0-1_3.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "EchoSched",
    "instance": "15-15-0-1_3.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "hitori",
    "instance": "h20-2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "hitori",
    "instance": "h20-2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "EchoSched",
    "instance": "12-12-0-1_7.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "EchoSched",
    "instance": "12-12-0-1_7.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 161
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_12_h27_r0.05_s0.5_3.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "hitori",
    "instance": "h14-1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "hitori",
    "instance": "h14-1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "EchoSched",
    "instance": "13-14-0-2_6.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "EchoSched",
    "instance": "13-14-0-2_6.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_8_h16_r0.05_s0.5_3.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 4377
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_8_h16_r0.05_s0.5_3.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-kletzander",
    "instance": "test05.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-kletzander",
    "instance": "test05.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "EchoSched",
    "instance": "14-10-0-2_1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "EchoSched",
    "instance": "14-10-0-2_1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_3_h39_r0.05_s0.5_0.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 4479
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "cgt",
    "instance": "cgt_3_h39_r0.05_s0.5_0.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-kletzander",
    "instance": "test03.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-kletzander",
    "instance": "test03.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "EchoSched",
    "instance": "14-10-0-2_3.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "EchoSched",
    "instance": "14-10-0-2_3.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "EchoSched",
    "instance": "15-15-0-1_3.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "EchoSched",
    "instance": "15-15-0-1_3.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-kletzander",
    "instance": "i09.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-kletzander",
    "instance": "i09.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "fbd1",
    "instance": "FBDk04.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "fbd1",
    "instance": "FBDk04.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "EchoSched",
    "instance": "12-12-0-1_7.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "EchoSched",
    "instance": "12-12-0-1_7.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-kletzander",
    "instance": "i02.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-kletzander",
    "instance": "i02.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "fbd1",
    "instance": "FBDk06.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "fbd1",
    "instance": "FBDk06.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "EchoSched",
    "instance": "13-14-0-2_6.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "EchoSched",
    "instance": "13-14-0-2_6.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-kletzander",
    "instance": "i07.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-kletzander",
    "instance": "i07.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "fbd1",
    "instance": "FBDk08.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "fbd1",
    "instance": "FBDk08.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "EchoSched",
    "instance": "14-10-0-2_1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "EchoSched",
    "instance": "14-10-0-2_1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-marte",
    "instance": "i14.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-marte",
    "instance": "i14.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "fbd1",
    "instance": "FBDk07.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "fbd1",
    "instance": "FBDk07.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "EchoSched",
    "instance": "14-10-0-2_3.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "EchoSched",
    "instance": "14-10-0-2_3.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-marte",
    "instance": "i06.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-marte",
    "instance": "i06.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "fbd1",
    "instance": "FBDk09.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "fbd1",
    "instance": "FBDk09.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "fbd1",
    "instance": "FBDk04.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "fbd1",
    "instance": "FBDk04.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-marte",
    "instance": "i01.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 1271
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-marte",
    "instance": "i01.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "fbd1",
    "instance": "FBDk06.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "fbd1",
    "instance": "FBDk06.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-marte",
    "instance": "i11.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-marte",
    "instance": "i11.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "fbd1",
    "instance": "FBDk08.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "fbd1",
    "instance": "FBDk08.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-marte",
    "instance": "i03.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "ihtc-2024-marte",
    "instance": "i03.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "groupsplitter",
    "instance": "u15g5pref1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "groupsplitter",
    "instance": "u15g5pref1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "fbd1",
    "instance": "FBDk07.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "fbd1",
    "instance": "FBDk07.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "is",
    "instance": "BnMUR3YMRk.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "is",
    "instance": "BnMUR3YMRk.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "groupsplitter",
    "instance": "u15g1pref2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "groupsplitter",
    "instance": "u15g1pref2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "fbd1",
    "instance": "FBDk09.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "fbd1",
    "instance": "FBDk09.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "is",
    "instance": "avdoaYnfXq.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "groupsplitter",
    "instance": "u15g3pref0.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "is",
    "instance": "avdoaYnfXq.dzn",
    "error": "Connection error."
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "groupsplitter",
    "instance": "u15g3pref0.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "groupsplitter",
    "instance": "u12g2pref0.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "is",
    "instance": "1vERFuvviS.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "is",
    "instance": "1vERFuvviS.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "gt-sort",
    "instance": "n9_ub10_50.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "gt-sort",
    "instance": "n9_ub10_50.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "groupsplitter",
    "instance": "u12g2pref2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "is",
    "instance": "9aGFgDaHX7.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "is",
    "instance": "9aGFgDaHX7.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "gt-sort",
    "instance": "n13_ub20_50.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "gt-sort",
    "instance": "n13_ub20_50.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "groupsplitter",
    "instance": "u15g5pref1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "groupsplitter",
    "instance": "u15g5pref1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "is",
    "instance": "vWQp9idqMs.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 7800
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "is",
    "instance": "vWQp9idqMs.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "gt-sort",
    "instance": "n7_ub20_75.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "gt-sort",
    "instance": "n7_ub20_75.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "groupsplitter",
    "instance": "u15g1pref2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "groupsplitter",
    "instance": "u15g1pref2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "mondoku",
    "instance": "12-12-8.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "mondoku",
    "instance": "12-12-8.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "gt-sort",
    "instance": "n9_ub10_75.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "gt-sort",
    "instance": "n9_ub10_75.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "groupsplitter",
    "instance": "u15g3pref0.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "groupsplitter",
    "instance": "u15g3pref0.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "mondoku",
    "instance": "20-18-9.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "mondoku",
    "instance": "20-18-9.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "gt-sort",
    "instance": "n9_ub30_35.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "gt-sort",
    "instance": "n9_ub30_35.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "gt-sort",
    "instance": "n9_ub10_50.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "gt-sort",
    "instance": "n9_ub10_50.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "mondoku",
    "instance": "14-14-8.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "mondoku",
    "instance": "14-14-8.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "hitori",
    "instance": "h11-1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "hitori",
    "instance": "h11-1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "gt-sort",
    "instance": "n13_ub20_50.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "gt-sort",
    "instance": "n13_ub20_50.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "mondoku",
    "instance": "8-8-4.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "mondoku",
    "instance": "8-8-4.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "hitori",
    "instance": "h5-1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "hitori",
    "instance": "h5-1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "gt-sort",
    "instance": "n7_ub20_75.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "gt-sort",
    "instance": "n7_ub20_75.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "mondoku",
    "instance": "10-10-6.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "mondoku",
    "instance": "10-10-6.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "hitori",
    "instance": "h15-1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "hitori",
    "instance": "h15-1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "gt-sort",
    "instance": "n9_ub10_75.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "gt-sort",
    "instance": "n9_ub10_75.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "products-and-shelves",
    "instance": "ps-25-03.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "products-and-shelves",
    "instance": "ps-25-03.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "hitori",
    "instance": "h20-2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "hitori",
    "instance": "h20-2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "gt-sort",
    "instance": "n9_ub30_35.0_BEST.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "gt-sort",
    "instance": "n9_ub30_35.0_BEST.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "products-and-shelves",
    "instance": "ps-25-01.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "products-and-shelves",
    "instance": "ps-25-01.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "hitori",
    "instance": "h14-1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "hitori",
    "instance": "h14-1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "hitori",
    "instance": "h11-1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "hitori",
    "instance": "h11-1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "products-and-shelves",
    "instance": "ps-50-06.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "products-and-shelves",
    "instance": "ps-50-06.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-kletzander",
    "instance": "test05.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-kletzander",
    "instance": "test05.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "hitori",
    "instance": "h5-1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "hitori",
    "instance": "h5-1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "products-and-shelves",
    "instance": "ps-50-09.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "products-and-shelves",
    "instance": "ps-50-09.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-kletzander",
    "instance": "test03.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-kletzander",
    "instance": "test03.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "hitori",
    "instance": "h15-1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "hitori",
    "instance": "h15-1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "products-and-shelves",
    "instance": "toy.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "products-and-shelves",
    "instance": "toy.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-kletzander",
    "instance": "i09.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-kletzander",
    "instance": "i09.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "hitori",
    "instance": "h20-2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "hitori",
    "instance": "h20-2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-kletzander",
    "instance": "i02.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-kletzander",
    "instance": "i02.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.19aa.usingEref_self.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.19aa.usingEref_self.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "hitori",
    "instance": "h14-1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "hitori",
    "instance": "h14-1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-kletzander",
    "instance": "i07.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-kletzander",
    "instance": "i07.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "proteindesign12",
    "instance": "2TRX.11p.8aa.usingEref_self_x.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "proteindesign12",
    "instance": "2TRX.11p.8aa.usingEref_self_x.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-kletzander",
    "instance": "test05.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-kletzander",
    "instance": "test05.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-marte",
    "instance": "i14.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-marte",
    "instance": "i14.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.9aa.usingEref_self_x.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.9aa.usingEref_self_x.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-kletzander",
    "instance": "test03.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-kletzander",
    "instance": "test03.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-marte",
    "instance": "i06.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-marte",
    "instance": "i06.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-kletzander",
    "instance": "i09.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-kletzander",
    "instance": "i09.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.19aa.usingEref_self.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.19aa.usingEref_self.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-marte",
    "instance": "i01.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 1271
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-marte",
    "instance": "i01.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-kletzander",
    "instance": "i02.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-kletzander",
    "instance": "i02.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.9aa.usingEref_self.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.9aa.usingEref_self.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-marte",
    "instance": "i11.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-marte",
    "instance": "i11.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-kletzander",
    "instance": "i07.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-kletzander",
    "instance": "i07.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_3m_3.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 1918
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_3m_3.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-marte",
    "instance": "i03.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "ihtc-2024-marte",
    "instance": "i03.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-marte",
    "instance": "i14.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-marte",
    "instance": "i14.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2w_2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6202
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2w_2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "is",
    "instance": "BnMUR3YMRk.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "is",
    "instance": "BnMUR3YMRk.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-marte",
    "instance": "i06.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-marte",
    "instance": "i06.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_5d_1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6620
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_5d_1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "is",
    "instance": "avdoaYnfXq.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "is",
    "instance": "avdoaYnfXq.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2m_2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 3709
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2m_2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-marte",
    "instance": "i01.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-marte",
    "instance": "i01.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "is",
    "instance": "1vERFuvviS.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "is",
    "instance": "1vERFuvviS.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_1m_2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 5340
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_1m_2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-marte",
    "instance": "i11.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-marte",
    "instance": "i11.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "is",
    "instance": "9aGFgDaHX7.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "is",
    "instance": "9aGFgDaHX7.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l12_c6_n12.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l12_c6_n12.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-marte",
    "instance": "i03.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "ihtc-2024-marte",
    "instance": "i03.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "is",
    "instance": "vWQp9idqMs.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 7800
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "is",
    "instance": "vWQp9idqMs.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "stripboard",
    "instance": "stripboard_w15_h10_l12_c6_n12.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "stripboard",
    "instance": "stripboard_w15_h10_l12_c6_n12.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "is",
    "instance": "BnMUR3YMRk.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "is",
    "instance": "BnMUR3YMRk.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "mondoku",
    "instance": "12-12-8.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "mondoku",
    "instance": "12-12-8.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l7_c6_n24.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l7_c6_n24.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "is",
    "instance": "avdoaYnfXq.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "is",
    "instance": "avdoaYnfXq.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "mondoku",
    "instance": "20-18-9.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "mondoku",
    "instance": "20-18-9.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "stripboard",
    "instance": "stripboard_w10_h10_l12_c4_n24.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "stripboard",
    "instance": "stripboard_w10_h10_l12_c4_n24.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "is",
    "instance": "1vERFuvviS.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "is",
    "instance": "1vERFuvviS.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "mondoku",
    "instance": "14-14-8.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "mondoku",
    "instance": "14-14-8.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l4_c4_n24.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l4_c4_n24.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "is",
    "instance": "9aGFgDaHX7.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "is",
    "instance": "9aGFgDaHX7.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "mondoku",
    "instance": "8-8-4.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "mondoku",
    "instance": "8-8-4.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tower",
    "instance": "tower_070_070_30_100-02.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 4949
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tower",
    "instance": "tower_070_070_30_100-02.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "is",
    "instance": "vWQp9idqMs.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 5800
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "is",
    "instance": "vWQp9idqMs.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "mondoku",
    "instance": "10-10-6.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "mondoku",
    "instance": "10-10-6.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tower",
    "instance": "tower_070_070_15_070-08.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 7991
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tower",
    "instance": "tower_070_070_15_070-08.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "mondoku",
    "instance": "12-12-8.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "mondoku",
    "instance": "12-12-8.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "products-and-shelves",
    "instance": "ps-25-03.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "products-and-shelves",
    "instance": "ps-25-03.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tower",
    "instance": "tower_070_070_15_070-02.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 7990
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tower",
    "instance": "tower_070_070_15_070-02.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "mondoku",
    "instance": "20-18-9.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "mondoku",
    "instance": "20-18-9.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "products-and-shelves",
    "instance": "ps-25-01.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "products-and-shelves",
    "instance": "ps-25-01.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tower",
    "instance": "tower_500_500_50_300-05.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tower",
    "instance": "tower_500_500_50_300-05.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "mondoku",
    "instance": "14-14-8.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "mondoku",
    "instance": "14-14-8.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "products-and-shelves",
    "instance": "ps-50-06.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "products-and-shelves",
    "instance": "ps-50-06.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tower",
    "instance": "tower_050_050_10_050-03.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tower",
    "instance": "tower_050_050_10_050-03.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "mondoku",
    "instance": "8-8-4.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "mondoku",
    "instance": "8-8-4.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "products-and-shelves",
    "instance": "ps-50-09.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "products-and-shelves",
    "instance": "ps-50-09.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tsptw",
    "instance": "n20w140.005.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tsptw",
    "instance": "n20w140.005.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "mondoku",
    "instance": "10-10-6.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "mondoku",
    "instance": "10-10-6.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "products-and-shelves",
    "instance": "toy.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "products-and-shelves",
    "instance": "toy.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tsptw",
    "instance": "n20w180.004.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tsptw",
    "instance": "n20w180.004.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "products-and-shelves",
    "instance": "ps-25-03.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "products-and-shelves",
    "instance": "ps-25-03.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tsptw",
    "instance": "n100w120.003.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tsptw",
    "instance": "n100w120.003.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.19aa.usingEref_self.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.19aa.usingEref_self.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "products-and-shelves",
    "instance": "ps-25-01.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "products-and-shelves",
    "instance": "ps-25-01.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tsptw",
    "instance": "n80w180.003.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 3030
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tsptw",
    "instance": "n80w180.003.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "proteindesign12",
    "instance": "2TRX.11p.8aa.usingEref_self_x.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "proteindesign12",
    "instance": "2TRX.11p.8aa.usingEref_self_x.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "products-and-shelves",
    "instance": "ps-50-06.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "products-and-shelves",
    "instance": "ps-50-06.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tsptw",
    "instance": "n20w160.001.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "tsptw",
    "instance": "n20w160.001.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.9aa.usingEref_self_x.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.9aa.usingEref_self_x.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "products-and-shelves",
    "instance": "ps-50-09.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "products-and-shelves",
    "instance": "ps-50-09.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "work-task-variation",
    "instance": "generated-seed-10-length-12-open-10-workers-12-block-5.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 5706
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "work-task-variation",
    "instance": "generated-seed-10-length-12-open-10-workers-12-block-5.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "products-and-shelves",
    "instance": "toy.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "products-and-shelves",
    "instance": "toy.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.19aa.usingEref_self.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.19aa.usingEref_self.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "work-task-variation",
    "instance": "generated-seed-1-length-16-open-14-workers-12-block-15.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 7920
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "work-task-variation",
    "instance": "generated-seed-1-length-16-open-14-workers-12-block-15.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.9aa.usingEref_self.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.9aa.usingEref_self.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.19aa.usingEref_self.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.19aa.usingEref_self.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "work-task-variation",
    "instance": "generated-seed-4-length-14-open-12-workers-12-block-15.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "work-task-variation",
    "instance": "generated-seed-4-length-14-open-12-workers-12-block-15.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_3m_3.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 1918
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_3m_3.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "proteindesign12",
    "instance": "2TRX.11p.8aa.usingEref_self_x.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "proteindesign12",
    "instance": "2TRX.11p.8aa.usingEref_self_x.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "work-task-variation",
    "instance": "generated-seed-8-length-12-open-10-workers-10-block-15.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "work-task-variation",
    "instance": "generated-seed-8-length-12-open-10-workers-10-block-15.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.9aa.usingEref_self_x.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.9aa.usingEref_self_x.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2w_2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6202
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2w_2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "work-task-variation",
    "instance": "generated-seed-3-length-10-open-8-workers-12-block-15.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct",
    "problem": "work-task-variation",
    "instance": "generated-seed-3-length-10-open-8-workers-12-block-15.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_5d_1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6620
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_5d_1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.19aa.usingEref_self.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "proteindesign12",
    "instance": "1UBI.13p.19aa.usingEref_self.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.9aa.usingEref_self.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "proteindesign12",
    "instance": "1HZ5.12p.9aa.usingEref_self.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2m_2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 3709
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2m_2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_1m_2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 5340
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_1m_2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_3m_3.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_3m_3.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2w_2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 4202
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2w_2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l12_c6_n12.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l12_c6_n12.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_5d_1.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 4620
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_5d_1.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "stripboard",
    "instance": "stripboard_w15_h10_l12_c6_n12.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "stripboard",
    "instance": "stripboard_w15_h10_l12_c6_n12.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2m_2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 1709
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_2m_2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l7_c6_n24.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l7_c6_n24.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_1m_2.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 3340
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "skill-allocation",
    "instance": "skill_allocation_mzn_1m_2.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "stripboard",
    "instance": "stripboard_w10_h10_l12_c4_n24.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "stripboard",
    "instance": "stripboard_w10_h10_l12_c4_n24.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l12_c6_n12.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l12_c6_n12.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l4_c4_n24.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l4_c4_n24.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "stripboard",
    "instance": "stripboard_w15_h10_l12_c6_n12.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "stripboard",
    "instance": "stripboard_w15_h10_l12_c6_n12.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tower",
    "instance": "tower_070_070_30_100-02.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 4949
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tower",
    "instance": "tower_070_070_30_100-02.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l7_c6_n24.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l7_c6_n24.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tower",
    "instance": "tower_070_070_15_070-08.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 7991
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tower",
    "instance": "tower_070_070_15_070-08.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "stripboard",
    "instance": "stripboard_w10_h10_l12_c4_n24.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "stripboard",
    "instance": "stripboard_w10_h10_l12_c4_n24.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tower",
    "instance": "tower_070_070_15_070-02.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 7990
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tower",
    "instance": "tower_070_070_15_070-02.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l4_c4_n24.json",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "stripboard",
    "instance": "stripboard_w20_h15_l4_c4_n24.json",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tower",
    "instance": "tower_500_500_50_300-05.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tower",
    "instance": "tower_500_500_50_300-05.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tower",
    "instance": "tower_070_070_30_100-02.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 2949
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tower",
    "instance": "tower_070_070_30_100-02.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tower",
    "instance": "tower_050_050_10_050-03.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tower",
    "instance": "tower_050_050_10_050-03.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tower",
    "instance": "tower_070_070_15_070-08.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 5991
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tower",
    "instance": "tower_070_070_15_070-08.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tsptw",
    "instance": "n20w140.005.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tsptw",
    "instance": "n20w140.005.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tower",
    "instance": "tower_070_070_15_070-02.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 5990
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tower",
    "instance": "tower_070_070_15_070-02.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tsptw",
    "instance": "n20w180.004.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tsptw",
    "instance": "n20w180.004.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tower",
    "instance": "tower_500_500_50_300-05.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tower",
    "instance": "tower_500_500_50_300-05.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tsptw",
    "instance": "n100w120.003.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tsptw",
    "instance": "n100w120.003.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tower",
    "instance": "tower_050_050_10_050-03.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tower",
    "instance": "tower_050_050_10_050-03.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tsptw",
    "instance": "n80w180.003.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 3030
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tsptw",
    "instance": "n80w180.003.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tsptw",
    "instance": "n20w140.005.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tsptw",
    "instance": "n20w140.005.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tsptw",
    "instance": "n20w160.001.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "tsptw",
    "instance": "n20w160.001.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tsptw",
    "instance": "n20w180.004.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tsptw",
    "instance": "n20w180.004.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "work-task-variation",
    "instance": "generated-seed-10-length-12-open-10-workers-12-block-5.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 5706
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "work-task-variation",
    "instance": "generated-seed-10-length-12-open-10-workers-12-block-5.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tsptw",
    "instance": "n100w120.003.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 0
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tsptw",
    "instance": "n100w120.003.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "work-task-variation",
    "instance": "generated-seed-1-length-16-open-14-workers-12-block-15.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 7920
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "work-task-variation",
    "instance": "generated-seed-1-length-16-open-14-workers-12-block-15.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tsptw",
    "instance": "n80w180.003.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 1030
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tsptw",
    "instance": "n80w180.003.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "work-task-variation",
    "instance": "generated-seed-4-length-14-open-12-workers-12-block-15.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "work-task-variation",
    "instance": "generated-seed-4-length-14-open-12-workers-12-block-15.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tsptw",
    "instance": "n20w160.001.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "tsptw",
    "instance": "n20w160.001.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "work-task-variation",
    "instance": "generated-seed-8-length-12-open-10-workers-10-block-15.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "work-task-variation",
    "instance": "generated-seed-8-length-12-open-10-workers-10-block-15.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "work-task-variation",
    "instance": "generated-seed-10-length-12-open-10-workers-12-block-5.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 3706
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "work-task-variation",
    "instance": "generated-seed-10-length-12-open-10-workers-12-block-5.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "work-task-variation",
    "instance": "generated-seed-3-length-10-open-8-workers-12-block-15.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 8000
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "moonshotai/kimi-k2-instruct-0905",
    "problem": "work-task-variation",
    "instance": "generated-seed-3-length-10-open-8-workers-12-block-15.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "work-task-variation",
    "instance": "generated-seed-1-length-16-open-14-workers-12-block-15.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 5920
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "work-task-variation",
    "instance": "generated-seed-1-length-16-open-14-workers-12-block-15.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "work-task-variation",
    "instance": "generated-seed-4-length-14-open-12-workers-12-block-15.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6184
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "work-task-variation",
    "instance": "generated-seed-4-length-14-open-12-workers-12-block-15.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "work-task-variation",
    "instance": "generated-seed-8-length-12-open-10-workers-10-block-15.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "work-task-variation",
    "instance": "generated-seed-8-length-12-open-10-workers-10-block-15.dzn",
    "error": "Connection error."
  },
  {
    "when": "query_attempt",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "work-task-variation",
    "instance": "generated-seed-3-length-10-open-8-workers-12-block-15.dzn",
    "error": "Connection error.",
    "size_error": false,
    "rate_error": false,
    "allowed_script_tokens": 6400
  },
  {
    "when": "task_result",
    "provider": "groq",
    "model": "openai/gpt-oss-120b",
    "problem": "work-task-variation",
    "instance": "generated-seed-3-length-10-open-8-workers-12-block-15.dzn",
    "error": "Connection error."
  }
]