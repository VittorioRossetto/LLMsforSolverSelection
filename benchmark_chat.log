2025-12-09 10:31:45,637 INFO Loaded mzn2feat features from /home/vro5/Coding/AgenticSolvers/test/data/mzn2feat_all_features.json
2025-12-09 10:31:46,054 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11884, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11884, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:31:46,060 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=15748 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 11884, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:31:46,060 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:31:46,076 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12040, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12040, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:31:46,080 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12040, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12040, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:31:46,080 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=15748 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12040, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:31:46,081 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=15748 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12040, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:31:46,081 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:31:46,081 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:32:13,768 ERROR send_chat error provider=gemini model=gemini-2.5-flash-lite: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash-lite\nPlease retry in 46.281035875s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 190, in send_chat
    response = client.models.generate_content(model=model_id, config=cfg, contents=contents)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/google/genai/models.py", line 6498, in generate_content
    response = self._generate_content(
               ^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/google/genai/models.py", line 5310, in _generate_content
    response = self._api_client.request(
               ^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/google/genai/_api_client.py", line 1291, in request
    response = self._request(http_request, http_options, stream=False)
               ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/google/genai/_api_client.py", line 1127, in _request
    return self._retry(self._request_once, http_request, stream)  # type: ignore[no-any-return]
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 477, in __call__
    do = self.iter(retry_state=retry_state)
         ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 378, in iter
    result = action(retry_state)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 420, in exc_check
    raise retry_exc.reraise()
          ^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 187, in reraise
    raise self.last_attempt.result()
          ^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 449, in result
    return self.__get_result()
           ^^^^^^^^^^^^^^^^^^^
  File "/usr/lib/python3.12/concurrent/futures/_base.py", line 401, in __get_result
    raise self._exception
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/tenacity/__init__.py", line 480, in __call__
    result = fn(*args, **kwargs)
             ^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/google/genai/_api_client.py", line 1104, in _request_once
    errors.APIError.raise_for_response(response)
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/google/genai/errors.py", line 108, in raise_for_response
    raise ClientError(status_code, response_json, response)
google.genai.errors.ClientError: 429 RESOURCE_EXHAUSTED. {'error': {'code': 429, 'message': 'You exceeded your current quota, please check your plan and billing details. For more information on this error, head to: https://ai.google.dev/gemini-api/docs/rate-limits. To monitor your current usage, head to: https://ai.dev/usage?tab=rate-limit. \n* Quota exceeded for metric: generativelanguage.googleapis.com/generate_content_free_tier_requests, limit: 10, model: gemini-2.5-flash-lite\nPlease retry in 46.281035875s.', 'status': 'RESOURCE_EXHAUSTED', 'details': [{'@type': 'type.googleapis.com/google.rpc.Help', 'links': [{'description': 'Learn more about Gemini API quotas', 'url': 'https://ai.google.dev/gemini-api/docs/rate-limits'}]}, {'@type': 'type.googleapis.com/google.rpc.QuotaFailure', 'violations': [{'quotaMetric': 'generativelanguage.googleapis.com/generate_content_free_tier_requests', 'quotaId': 'GenerateRequestsPerMinutePerProjectPerModel-FreeTier', 'quotaDimensions': {'location': 'global', 'model': 'gemini-2.5-flash-lite'}, 'quotaValue': '10'}]}, {'@type': 'type.googleapis.com/google.rpc.RetryInfo', 'retryDelay': '46s'}]}}
2025-12-09 10:32:13,783 INFO Received rate-limit/429 for provider=gemini model=gemini-2.5-flash-lite; sleeping 60s before retry
2025-12-09 10:32:32,607 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9110, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9110, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:32:32,610 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=13874 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9110, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:32:32,610 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:33:07,646 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13630, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13630, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:33:07,648 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=16881 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13630, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:33:07,648 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:33:07,652 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13630, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13630, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:33:07,655 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=16881 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13630, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:33:07,655 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:33:46,005 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 13466, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 13466, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:33:46,007 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=16881 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 13466, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:33:46,007 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:34:39,457 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 8903, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 8903, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:34:39,458 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=10771 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 8903, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:34:39,458 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:34:43,657 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10199, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10199, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:34:43,658 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=14436 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10199, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:34:43,658 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:34:43,680 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10199, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10199, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:34:43,682 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=14436 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10199, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:34:43,682 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:35:49,647 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11018, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11018, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:35:49,654 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=14736 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11018, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:35:49,655 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:35:49,710 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11018, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11018, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:35:49,711 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=14736 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11018, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:35:49,711 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:36:06,601 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 10034, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 10034, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:36:06,602 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=14436 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 10034, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:36:06,602 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:37:30,573 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 10864, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 10864, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:37:30,575 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=14736 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 10864, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:37:30,575 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:37:53,889 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 14649, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 14649, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:37:53,891 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=17338 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 14649, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:37:53,892 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:37:53,908 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 14649, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 14649, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:37:53,911 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=17338 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 14649, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:37:53,912 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:38:57,403 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 8933, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 8933, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:38:57,405 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=13768 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 8933, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:38:57,405 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:40:10,791 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 14507, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 14507, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:40:10,794 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=17338 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 14507, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:40:10,794 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:40:22,159 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10529, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10529, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:40:22,163 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=14665 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10529, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:40:22,163 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:40:24,735 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10529, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10529, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:40:24,737 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=14665 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10529, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:40:24,738 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:41:03,865 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9461, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9461, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:41:03,866 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=11024 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9461, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:41:03,866 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:41:33,361 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 15055, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 15055, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:41:33,362 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=16720 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 15055, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:41:33,362 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:41:36,190 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 15055, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 15055, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:41:36,190 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=16720 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 15055, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:41:36,191 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:42:24,244 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 16848, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 16848, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:42:24,248 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=19881 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 16848, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:42:24,248 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:42:30,877 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9707, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9707, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:42:30,879 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=14043 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9707, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:42:30,880 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:42:33,464 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 16848, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 16848, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:42:33,466 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=19881 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 16848, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:42:33,466 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:43:23,784 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12171, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12171, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:43:23,787 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=13668 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12171, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:43:23,787 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:43:28,224 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12171, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12171, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:43:28,227 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=13668 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12171, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:43:28,227 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:43:40,815 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 10364, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 10364, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:43:40,818 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=14665 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 10364, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:43:40,818 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:44:15,837 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 17979, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 17979, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:44:15,839 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=19766 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 17979, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:44:15,840 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:44:37,036 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 17979, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 17979, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:44:37,036 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=19766 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 17979, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:44:37,036 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:44:59,385 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12225, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12225, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:44:59,388 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=12945 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12225, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:44:59,388 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:45:06,630 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12225, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12225, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:45:06,633 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=12945 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12225, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:45:06,636 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:45:11,133 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 14884, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 14884, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:45:11,133 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=16720 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 14884, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:45:11,134 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:46:02,541 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9276, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9276, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:46:02,544 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=10314 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9276, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:46:02,544 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:46:26,186 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11075, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11075, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:46:26,189 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=15881 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11075, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:46:26,189 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:47:11,150 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11075, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11075, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:47:11,153 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=15881 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11075, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:47:11,153 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:47:16,448 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 16618, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 16618, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:47:16,449 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=19881 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 16618, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:47:16,449 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:47:16,574 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9784, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9784, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:47:16,575 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=10567 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9784, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:47:16,575 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 10:47:37,434 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13003, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13003, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:47:37,435 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=15814 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13003, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:47:37,435 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:48:21,446 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13003, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13003, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:48:21,447 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=15814 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13003, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:48:21,447 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:48:56,809 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11362, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11362, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:48:56,810 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=15092 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11362, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:48:56,810 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:49:06,645 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189985, Requested 12035. Please try again in 14m32.64s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189985, Requested 12035. Please try again in 14m32.64s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:49:06,647 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 10:49:44,240 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11362, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11362, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:49:44,242 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=15092 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11362, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:49:44,242 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:50:06,839 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189845, Requested 12035. Please try again in 13m32.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189845, Requested 12035. Please try again in 13m32.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:50:06,846 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 10:50:08,084 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13293, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13293, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:50:08,086 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=16485 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13293, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:50:08,086 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:50:10,199 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13293, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13293, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:50:10,202 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=16485 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 13293, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:50:10,202 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:51:03,379 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12980, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12980, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:51:03,381 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=15672 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12980, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:51:03,381 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:51:07,068 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189705, Requested 12035. Please try again in 12m31.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189705, Requested 12035. Please try again in 12m31.68s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:51:07,070 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 10:51:32,402 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12980, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12980, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:51:32,405 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=15672 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 12980, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:51:32,406 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:52:07,170 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189566, Requested 12035. Please try again in 11m31.632s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189566, Requested 12035. Please try again in 11m31.632s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:52:07,171 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 10:52:17,541 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10292, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10292, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:52:17,542 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=14441 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10292, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:52:17,542 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:52:26,586 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10292, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10292, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:52:26,589 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=14441 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 10292, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:52:26,589 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:53:01,489 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11824, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11824, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:53:01,569 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct: estimated_request_tokens=15530 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11824, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:53:01,569 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct
2025-12-09 10:53:07,491 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189427, Requested 12035. Please try again in 10m31.584s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189427, Requested 12035. Please try again in 10m31.584s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:53:07,491 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 10:53:21,055 ERROR send_chat error provider=groq model=moonshotai/kimi-k2-instruct-0905: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11824, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11824, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:53:21,057 WARNING SIZE/CONTEXT error detected for provider=groq model=moonshotai/kimi-k2-instruct-0905: estimated_request_tokens=15530 error=Error code: 413 - {'error': {'message': 'Request too large for model `moonshotai/kimi-k2-instruct-0905` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 10000, Requested 11824, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:53:21,057 INFO Splitting oversized request into 2 chats for provider=groq model=moonshotai/kimi-k2-instruct-0905
2025-12-09 10:54:07,637 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189287, Requested 12035. Please try again in 9m31.104s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189287, Requested 12035. Please try again in 9m31.104s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:54:07,640 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 10:55:07,792 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189149, Requested 12035. Please try again in 8m31.488s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189149, Requested 12035. Please try again in 8m31.488s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:55:07,795 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 10:56:07,941 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189010, Requested 12035. Please try again in 7m31.439999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189010, Requested 12035. Please try again in 7m31.439999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:56:07,944 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 10:57:08,152 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188870, Requested 12035. Please try again in 6m30.96s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188870, Requested 12035. Please try again in 6m30.96s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:57:08,154 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 10:58:08,265 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188730, Requested 12035. Please try again in 5m30.479999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188730, Requested 12035. Please try again in 5m30.479999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:58:08,268 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 10:59:08,400 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188591, Requested 12035. Please try again in 4m30.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188591, Requested 12035. Please try again in 4m30.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 10:59:08,401 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:00:08,564 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188452, Requested 12035. Please try again in 3m30.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188452, Requested 12035. Please try again in 3m30.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:00:08,567 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:01:08,903 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188312, Requested 12035. Please try again in 2m29.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188312, Requested 12035. Please try again in 2m29.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:01:08,905 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:02:09,113 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188173, Requested 12035. Please try again in 1m29.856s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188173, Requested 12035. Please try again in 1m29.856s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:02:09,116 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:03:09,328 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 12035, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 12035, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:03:09,331 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=13668 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 12035, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:03:09,331 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 11:03:10,143 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195758, Requested 9616. Please try again in 38m41.568s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195758, Requested 9616. Please try again in 38m41.568s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:03:10,164 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:04:10,359 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195619, Requested 9616. Please try again in 37m41.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195619, Requested 9616. Please try again in 37m41.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:04:10,362 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:05:11,800 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195477, Requested 9616. Please try again in 36m40.176s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195477, Requested 9616. Please try again in 36m40.176s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:05:11,803 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:06:12,014 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195338, Requested 9616. Please try again in 35m40.128s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195338, Requested 9616. Please try again in 35m40.128s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:06:12,016 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:07:12,131 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195198, Requested 9616. Please try again in 34m39.648s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195198, Requested 9616. Please try again in 34m39.648s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:07:12,134 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:08:12,335 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195059, Requested 9616. Please try again in 33m39.6s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195059, Requested 9616. Please try again in 33m39.6s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:08:12,337 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:09:12,512 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194919, Requested 9616. Please try again in 32m39.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194919, Requested 9616. Please try again in 32m39.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:09:12,514 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:10:12,762 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194780, Requested 9616. Please try again in 31m39.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194780, Requested 9616. Please try again in 31m39.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:10:12,765 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:11:12,994 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194641, Requested 9616. Please try again in 30m39.024s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194641, Requested 9616. Please try again in 30m39.024s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:11:12,995 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:12:13,184 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194501, Requested 9616. Please try again in 29m38.543999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194501, Requested 9616. Please try again in 29m38.543999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:12:13,185 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:13:13,309 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194362, Requested 9616. Please try again in 28m38.496s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194362, Requested 9616. Please try again in 28m38.496s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:13:13,311 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:14:13,419 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194223, Requested 9616. Please try again in 27m38.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194223, Requested 9616. Please try again in 27m38.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:14:13,420 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:15:14,080 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194083, Requested 9616. Please try again in 26m37.968s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194083, Requested 9616. Please try again in 26m37.968s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:15:14,084 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:16:14,223 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193943, Requested 9616. Please try again in 25m37.487999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193943, Requested 9616. Please try again in 25m37.487999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:16:14,244 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:17:14,417 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193804, Requested 9616. Please try again in 24m37.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193804, Requested 9616. Please try again in 24m37.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:17:14,419 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:18:14,644 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193665, Requested 9616. Please try again in 23m37.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193665, Requested 9616. Please try again in 23m37.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:18:14,646 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:19:14,953 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193525, Requested 9616. Please try again in 22m36.912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193525, Requested 9616. Please try again in 22m36.912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:19:14,956 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:20:21,261 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193372, Requested 9616. Please try again in 21m30.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193372, Requested 9616. Please try again in 21m30.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:20:21,262 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:21:26,388 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193221, Requested 9616. Please try again in 20m25.584s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193221, Requested 9616. Please try again in 20m25.584s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:21:26,389 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:22:26,500 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193082, Requested 9616. Please try again in 19m25.536s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193082, Requested 9616. Please try again in 19m25.536s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:22:26,503 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:23:26,623 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192942, Requested 9616. Please try again in 18m25.056s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192942, Requested 9616. Please try again in 18m25.056s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:23:26,624 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:24:26,709 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192803, Requested 9616. Please try again in 17m25.008s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192803, Requested 9616. Please try again in 17m25.008s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:24:26,709 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:25:26,931 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192664, Requested 9616. Please try again in 16m24.96s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192664, Requested 9616. Please try again in 16m24.96s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:25:26,934 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:26:27,041 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192525, Requested 9616. Please try again in 15m24.911999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192525, Requested 9616. Please try again in 15m24.911999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:26:27,042 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:27:27,147 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192386, Requested 9616. Please try again in 14m24.864s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192386, Requested 9616. Please try again in 14m24.864s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:27:27,148 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:28:27,255 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192246, Requested 9616. Please try again in 13m24.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192246, Requested 9616. Please try again in 13m24.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:28:27,259 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:29:27,827 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192108, Requested 9616. Please try again in 12m24.767999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192108, Requested 9616. Please try again in 12m24.767999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:29:27,838 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:30:28,200 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191967, Requested 9616. Please try again in 11m23.856s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191967, Requested 9616. Please try again in 11m23.856s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:30:28,202 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:31:28,436 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191827, Requested 9616. Please try again in 10m23.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191827, Requested 9616. Please try again in 10m23.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:31:28,436 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:32:28,543 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191688, Requested 9616. Please try again in 9m23.328s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191688, Requested 9616. Please try again in 9m23.328s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:32:28,546 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:33:28,750 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191549, Requested 9616. Please try again in 8m23.28s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191549, Requested 9616. Please try again in 8m23.28s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:33:28,755 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:34:28,967 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191409, Requested 9616. Please try again in 7m22.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191409, Requested 9616. Please try again in 7m22.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:34:28,970 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:35:29,383 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191270, Requested 9616. Please try again in 6m22.752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191270, Requested 9616. Please try again in 6m22.752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:35:29,385 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:36:29,596 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191130, Requested 9616. Please try again in 5m22.272s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191130, Requested 9616. Please try again in 5m22.272s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:36:29,599 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:37:29,808 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190991, Requested 9616. Please try again in 4m22.224s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190991, Requested 9616. Please try again in 4m22.224s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:37:29,812 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:38:29,933 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190851, Requested 9616. Please try again in 3m21.744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190851, Requested 9616. Please try again in 3m21.744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:38:29,936 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:39:30,128 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190712, Requested 9616. Please try again in 2m21.696s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190712, Requested 9616. Please try again in 2m21.696s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:39:30,131 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:40:30,404 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190573, Requested 9616. Please try again in 1m21.648s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190573, Requested 9616. Please try again in 1m21.648s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:40:30,404 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:41:52,800 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9616, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9616, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:41:52,801 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=10470 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9616, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:41:52,801 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 11:41:53,614 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197912, Requested 7420. Please try again in 38m23.424s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197912, Requested 7420. Please try again in 38m23.424s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:41:53,615 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:42:53,690 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197773, Requested 7420. Please try again in 37m23.375999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197773, Requested 7420. Please try again in 37m23.375999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:42:53,692 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:43:53,790 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197634, Requested 7420. Please try again in 36m23.328s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197634, Requested 7420. Please try again in 36m23.328s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:43:53,791 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:44:53,873 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197495, Requested 7420. Please try again in 35m23.279999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197495, Requested 7420. Please try again in 35m23.279999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:44:53,875 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:45:54,001 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197356, Requested 7420. Please try again in 34m23.232s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197356, Requested 7420. Please try again in 34m23.232s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:45:54,004 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:46:54,143 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197217, Requested 7420. Please try again in 33m23.184s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197217, Requested 7420. Please try again in 33m23.184s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:46:54,145 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:47:54,236 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197077, Requested 7420. Please try again in 32m22.704s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197077, Requested 7420. Please try again in 32m22.704s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:47:54,238 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:48:54,340 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196938, Requested 7420. Please try again in 31m22.656s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196938, Requested 7420. Please try again in 31m22.656s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:48:54,342 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:49:54,423 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196799, Requested 7420. Please try again in 30m22.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196799, Requested 7420. Please try again in 30m22.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:49:54,424 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:50:56,072 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196657, Requested 7420. Please try again in 29m21.264s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196657, Requested 7420. Please try again in 29m21.264s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:50:56,075 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:51:56,150 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196517, Requested 7420. Please try again in 28m20.784s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196517, Requested 7420. Please try again in 28m20.784s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:51:56,152 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:52:56,261 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196378, Requested 7420. Please try again in 27m20.736s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196378, Requested 7420. Please try again in 27m20.736s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:52:56,264 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:53:56,376 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196239, Requested 7420. Please try again in 26m20.687999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196239, Requested 7420. Please try again in 26m20.687999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:53:56,376 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:54:56,472 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196101, Requested 7420. Please try again in 25m21.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196101, Requested 7420. Please try again in 25m21.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:54:56,472 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:55:56,644 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195961, Requested 7420. Please try again in 24m20.592s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195961, Requested 7420. Please try again in 24m20.592s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:55:56,646 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:56:56,713 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195822, Requested 7420. Please try again in 23m20.543999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195822, Requested 7420. Please try again in 23m20.543999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:56:56,713 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:57:56,792 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195683, Requested 7420. Please try again in 22m20.495999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195683, Requested 7420. Please try again in 22m20.495999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:57:56,793 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:58:56,873 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195544, Requested 7420. Please try again in 21m20.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195544, Requested 7420. Please try again in 21m20.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:58:56,874 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 11:59:56,940 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195405, Requested 7420. Please try again in 20m20.4s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195405, Requested 7420. Please try again in 20m20.4s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 11:59:56,940 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:00:57,174 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195266, Requested 7420. Please try again in 19m20.351999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195266, Requested 7420. Please try again in 19m20.351999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:00:57,174 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:01:57,279 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195126, Requested 7420. Please try again in 18m19.872s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195126, Requested 7420. Please try again in 18m19.872s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:01:57,282 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:02:57,403 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194987, Requested 7420. Please try again in 17m19.824s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194987, Requested 7420. Please try again in 17m19.824s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:02:57,406 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:03:57,485 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194848, Requested 7420. Please try again in 16m19.776s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194848, Requested 7420. Please try again in 16m19.776s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:03:57,486 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:04:57,565 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194709, Requested 7420. Please try again in 15m19.728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194709, Requested 7420. Please try again in 15m19.728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:04:57,567 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:05:57,807 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194569, Requested 7420. Please try again in 14m19.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194569, Requested 7420. Please try again in 14m19.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:05:57,810 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:06:57,929 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194431, Requested 7420. Please try again in 13m19.632s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194431, Requested 7420. Please try again in 13m19.632s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:06:57,931 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:07:58,044 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194292, Requested 7420. Please try again in 12m19.584s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194292, Requested 7420. Please try again in 12m19.584s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:07:58,045 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:08:58,118 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194153, Requested 7420. Please try again in 11m19.536s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194153, Requested 7420. Please try again in 11m19.536s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:08:58,120 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:09:58,249 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194013, Requested 7420. Please try again in 10m19.056s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194013, Requested 7420. Please try again in 10m19.056s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:09:58,250 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:10:58,357 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193873, Requested 7420. Please try again in 9m18.576s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193873, Requested 7420. Please try again in 9m18.576s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:10:58,360 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:11:58,611 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193734, Requested 7420. Please try again in 8m18.528s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193734, Requested 7420. Please try again in 8m18.528s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:11:58,614 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:12:58,704 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193595, Requested 7420. Please try again in 7m18.479999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193595, Requested 7420. Please try again in 7m18.479999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:12:58,706 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:13:58,776 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193456, Requested 7420. Please try again in 6m18.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193456, Requested 7420. Please try again in 6m18.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:13:58,777 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:14:58,885 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193317, Requested 7420. Please try again in 5m18.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193317, Requested 7420. Please try again in 5m18.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:14:58,887 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:15:59,010 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193178, Requested 7420. Please try again in 4m18.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193178, Requested 7420. Please try again in 4m18.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:15:59,010 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:16:59,131 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193038, Requested 7420. Please try again in 3m17.856s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193038, Requested 7420. Please try again in 3m17.856s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:16:59,134 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:17:59,228 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192899, Requested 7420. Please try again in 2m17.808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192899, Requested 7420. Please try again in 2m17.808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:17:59,231 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:18:59,323 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192760, Requested 7420. Please try again in 1m17.759999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192760, Requested 7420. Please try again in 1m17.759999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:18:59,327 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:20:18,414 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 200000, Requested 17834. Please try again in 2h8m24.288s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 200000, Requested 17834. Please try again in 2h8m24.288s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:20:18,415 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:21:18,560 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199861, Requested 17834. Please try again in 2h7m24.24s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199861, Requested 17834. Please try again in 2h7m24.24s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:21:18,561 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:22:18,698 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199722, Requested 17834. Please try again in 2h6m24.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199722, Requested 17834. Please try again in 2h6m24.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:22:18,699 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:23:18,845 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199583, Requested 17834. Please try again in 2h5m24.143999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199583, Requested 17834. Please try again in 2h5m24.143999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:23:18,845 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:24:19,077 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 17834. Please try again in 2h4m23.664s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 17834. Please try again in 2h4m23.664s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:24:19,079 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:25:20,468 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199301, Requested 17834. Please try again in 2h3m22.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199301, Requested 17834. Please try again in 2h3m22.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:25:20,470 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:26:25,622 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199150, Requested 17834. Please try again in 2h2m17.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199150, Requested 17834. Please try again in 2h2m17.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:26:25,623 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:27:25,743 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199011, Requested 17834. Please try again in 2h1m17.039999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199011, Requested 17834. Please try again in 2h1m17.039999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:27:25,744 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:28:25,855 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198872, Requested 17834. Please try again in 2h0m16.991999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198872, Requested 17834. Please try again in 2h0m16.991999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:28:25,858 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:29:26,011 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198733, Requested 17834. Please try again in 1h59m16.944s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198733, Requested 17834. Please try again in 1h59m16.944s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:29:26,012 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:30:26,155 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198593, Requested 17834. Please try again in 1h58m16.464s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198593, Requested 17834. Please try again in 1h58m16.464s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:30:26,157 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:31:26,374 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198454, Requested 17834. Please try again in 1h57m16.416s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198454, Requested 17834. Please try again in 1h57m16.416s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:31:26,377 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:32:26,507 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198315, Requested 17834. Please try again in 1h56m16.367999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198315, Requested 17834. Please try again in 1h56m16.367999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:32:26,508 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:33:26,599 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198176, Requested 17834. Please try again in 1h55m16.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198176, Requested 17834. Please try again in 1h55m16.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:33:26,601 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:34:26,715 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198037, Requested 17834. Please try again in 1h54m16.272s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198037, Requested 17834. Please try again in 1h54m16.272s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:34:26,715 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:35:26,799 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197897, Requested 17834. Please try again in 1h53m15.792s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197897, Requested 17834. Please try again in 1h53m15.792s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:35:26,799 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:36:27,062 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197758, Requested 17834. Please try again in 1h52m15.744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197758, Requested 17834. Please try again in 1h52m15.744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:36:27,064 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:37:27,242 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197619, Requested 17834. Please try again in 1h51m15.696s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197619, Requested 17834. Please try again in 1h51m15.696s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:37:27,244 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:38:27,399 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197479, Requested 17834. Please try again in 1h50m15.215999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197479, Requested 17834. Please try again in 1h50m15.215999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:38:27,401 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:39:27,500 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197340, Requested 17834. Please try again in 1h49m15.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197340, Requested 17834. Please try again in 1h49m15.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:39:27,500 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:40:27,608 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197201, Requested 17834. Please try again in 1h48m15.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197201, Requested 17834. Please try again in 1h48m15.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:40:27,610 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:41:27,818 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197062, Requested 17834. Please try again in 1h47m15.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197062, Requested 17834. Please try again in 1h47m15.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:41:27,819 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:42:27,942 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196923, Requested 17834. Please try again in 1h46m15.024s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196923, Requested 17834. Please try again in 1h46m15.024s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:42:27,945 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:43:28,136 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196783, Requested 17834. Please try again in 1h45m14.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196783, Requested 17834. Please try again in 1h45m14.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:43:28,136 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:44:28,326 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196644, Requested 17834. Please try again in 1h44m14.496s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196644, Requested 17834. Please try again in 1h44m14.496s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:44:28,327 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:45:28,537 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196505, Requested 17834. Please try again in 1h43m14.447999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196505, Requested 17834. Please try again in 1h43m14.447999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:45:28,538 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:46:28,909 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196365, Requested 17834. Please try again in 1h42m13.968s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196365, Requested 17834. Please try again in 1h42m13.968s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:46:28,910 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:47:29,165 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196225, Requested 17834. Please try again in 1h41m13.487999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196225, Requested 17834. Please try again in 1h41m13.487999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:47:29,166 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:48:29,291 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196086, Requested 17834. Please try again in 1h40m13.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196086, Requested 17834. Please try again in 1h40m13.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:48:29,293 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:49:29,489 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195947, Requested 17834. Please try again in 1h39m13.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195947, Requested 17834. Please try again in 1h39m13.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:49:29,491 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:50:29,678 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195807, Requested 17834. Please try again in 1h38m12.912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195807, Requested 17834. Please try again in 1h38m12.912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:50:29,680 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:51:30,009 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195668, Requested 17834. Please try again in 1h37m12.864s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195668, Requested 17834. Please try again in 1h37m12.864s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:51:30,011 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:52:30,221 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195529, Requested 17834. Please try again in 1h36m12.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195529, Requested 17834. Please try again in 1h36m12.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:52:30,224 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:53:30,417 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195389, Requested 17834. Please try again in 1h35m12.335999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195389, Requested 17834. Please try again in 1h35m12.335999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:53:30,420 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:54:30,646 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195250, Requested 17834. Please try again in 1h34m12.288s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195250, Requested 17834. Please try again in 1h34m12.288s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:54:30,650 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:55:30,857 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195110, Requested 17834. Please try again in 1h33m11.808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195110, Requested 17834. Please try again in 1h33m11.808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:55:30,859 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:56:31,146 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194971, Requested 17834. Please try again in 1h32m11.76s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194971, Requested 17834. Please try again in 1h32m11.76s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:56:31,150 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:57:31,382 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194831, Requested 17834. Please try again in 1h31m11.28s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194831, Requested 17834. Please try again in 1h31m11.28s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:57:31,385 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:58:31,592 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194692, Requested 17834. Please try again in 1h30m11.232s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194692, Requested 17834. Please try again in 1h30m11.232s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:58:31,594 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 12:59:31,799 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194553, Requested 17834. Please try again in 1h29m11.183999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194553, Requested 17834. Please try again in 1h29m11.183999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 12:59:31,802 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:00:31,957 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194413, Requested 17834. Please try again in 1h28m10.704s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194413, Requested 17834. Please try again in 1h28m10.704s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:00:31,959 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=19766 error=Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194413, Requested 17834. Please try again in 1h28m10.704s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:00:31,960 INFO Received size/context error (413) for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:01:32,230 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194274, Requested 17834. Please try again in 1h27m10.656s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194274, Requested 17834. Please try again in 1h27m10.656s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:01:32,233 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:02:32,531 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194134, Requested 17834. Please try again in 1h26m10.175999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194134, Requested 17834. Please try again in 1h26m10.175999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:02:32,534 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=19766 error=Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194134, Requested 17834. Please try again in 1h26m10.175999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:02:32,534 INFO Received size/context error (413) for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:03:32,740 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193995, Requested 17834. Please try again in 1h25m10.128s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193995, Requested 17834. Please try again in 1h25m10.128s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:03:32,743 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:04:33,070 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193855, Requested 17834. Please try again in 1h24m9.648s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193855, Requested 17834. Please try again in 1h24m9.648s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:04:33,073 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:05:33,198 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193716, Requested 17834. Please try again in 1h23m9.6s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193716, Requested 17834. Please try again in 1h23m9.6s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:05:33,199 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:06:33,329 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193577, Requested 17834. Please try again in 1h22m9.552s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193577, Requested 17834. Please try again in 1h22m9.552s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:06:33,330 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:07:33,578 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193438, Requested 17834. Please try again in 1h21m9.504s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193438, Requested 17834. Please try again in 1h21m9.504s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:07:33,580 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:08:33,794 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193298, Requested 17834. Please try again in 1h20m9.024s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193298, Requested 17834. Please try again in 1h20m9.024s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:08:33,797 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:09:33,920 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193159, Requested 17834. Please try again in 1h19m8.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193159, Requested 17834. Please try again in 1h19m8.976s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:09:33,921 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:10:34,105 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193019, Requested 17834. Please try again in 1h18m8.496s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193019, Requested 17834. Please try again in 1h18m8.496s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:10:34,108 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:11:34,384 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192880, Requested 17834. Please try again in 1h17m8.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192880, Requested 17834. Please try again in 1h17m8.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:11:34,387 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:12:34,524 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192741, Requested 17834. Please try again in 1h16m8.4s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192741, Requested 17834. Please try again in 1h16m8.4s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:12:34,525 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:13:34,752 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192601, Requested 17834. Please try again in 1h15m7.92s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192601, Requested 17834. Please try again in 1h15m7.92s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:13:34,755 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:14:34,958 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192462, Requested 17834. Please try again in 1h14m7.871999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192462, Requested 17834. Please try again in 1h14m7.871999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:14:34,960 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:15:35,149 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192322, Requested 17834. Please try again in 1h13m7.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192322, Requested 17834. Please try again in 1h13m7.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:15:35,152 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:16:35,573 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192183, Requested 17834. Please try again in 1h12m7.344s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192183, Requested 17834. Please try again in 1h12m7.344s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:16:35,576 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:17:35,886 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192043, Requested 17834. Please try again in 1h11m6.863999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192043, Requested 17834. Please try again in 1h11m6.863999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:17:35,887 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:18:36,095 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191904, Requested 17834. Please try again in 1h10m6.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191904, Requested 17834. Please try again in 1h10m6.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:18:36,096 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:19:36,250 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191764, Requested 17834. Please try again in 1h9m6.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191764, Requested 17834. Please try again in 1h9m6.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:19:36,253 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:20:36,400 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191625, Requested 17834. Please try again in 1h8m6.287999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191625, Requested 17834. Please try again in 1h8m6.287999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:20:36,403 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:21:36,831 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191485, Requested 17834. Please try again in 1h7m5.808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191485, Requested 17834. Please try again in 1h7m5.808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:21:36,834 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:22:37,043 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191346, Requested 17834. Please try again in 1h6m5.76s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191346, Requested 17834. Please try again in 1h6m5.76s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:22:37,045 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:23:37,251 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191207, Requested 17834. Please try again in 1h5m5.712s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191207, Requested 17834. Please try again in 1h5m5.712s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:23:37,252 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:24:37,463 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191067, Requested 17834. Please try again in 1h4m5.232s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191067, Requested 17834. Please try again in 1h4m5.232s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:24:37,464 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:25:37,675 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190928, Requested 17834. Please try again in 1h3m5.184s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190928, Requested 17834. Please try again in 1h3m5.184s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:25:37,678 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:26:37,907 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190788, Requested 17834. Please try again in 1h2m4.704s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190788, Requested 17834. Please try again in 1h2m4.704s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:26:37,908 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:27:38,136 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190649, Requested 17834. Please try again in 1h1m4.656s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190649, Requested 17834. Please try again in 1h1m4.656s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:27:38,138 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:28:38,384 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190510, Requested 17834. Please try again in 1h0m4.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190510, Requested 17834. Please try again in 1h0m4.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:28:38,386 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:29:38,533 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190370, Requested 17834. Please try again in 59m4.128s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190370, Requested 17834. Please try again in 59m4.128s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:29:38,536 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:30:38,732 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190231, Requested 17834. Please try again in 58m4.08s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190231, Requested 17834. Please try again in 58m4.08s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:30:38,734 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:31:38,944 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190091, Requested 17834. Please try again in 57m3.6s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190091, Requested 17834. Please try again in 57m3.6s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:31:38,947 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:32:39,134 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189952, Requested 17834. Please try again in 56m3.552s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189952, Requested 17834. Please try again in 56m3.552s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:32:39,136 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:33:39,267 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189813, Requested 17834. Please try again in 55m3.504s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189813, Requested 17834. Please try again in 55m3.504s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:33:39,269 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:34:39,480 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189674, Requested 17834. Please try again in 54m3.455999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189674, Requested 17834. Please try again in 54m3.455999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:34:39,483 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:35:39,695 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189534, Requested 17834. Please try again in 53m2.975999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189534, Requested 17834. Please try again in 53m2.975999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:35:39,697 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:36:40,111 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189394, Requested 17834. Please try again in 52m2.496s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189394, Requested 17834. Please try again in 52m2.496s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:36:40,112 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:37:40,323 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189255, Requested 17834. Please try again in 51m2.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189255, Requested 17834. Please try again in 51m2.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:37:40,326 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:38:40,441 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189116, Requested 17834. Please try again in 50m2.4s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189116, Requested 17834. Please try again in 50m2.4s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:38:40,443 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:39:40,645 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188976, Requested 17834. Please try again in 49m1.919999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188976, Requested 17834. Please try again in 49m1.919999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:39:40,647 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:40:40,781 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188837, Requested 17834. Please try again in 48m1.872s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188837, Requested 17834. Please try again in 48m1.872s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:40:40,783 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:41:40,968 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188698, Requested 17834. Please try again in 47m1.824s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188698, Requested 17834. Please try again in 47m1.824s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:41:40,969 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:42:41,180 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188559, Requested 17834. Please try again in 46m1.776s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188559, Requested 17834. Please try again in 46m1.776s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:42:41,183 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:43:41,391 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188419, Requested 17834. Please try again in 45m1.296s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188419, Requested 17834. Please try again in 45m1.296s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:43:41,392 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:44:41,604 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188280, Requested 17834. Please try again in 44m1.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188280, Requested 17834. Please try again in 44m1.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:44:41,606 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:45:41,814 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188141, Requested 17834. Please try again in 43m1.2s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188141, Requested 17834. Please try again in 43m1.2s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:45:41,815 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:46:42,234 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188001, Requested 17834. Please try again in 42m0.72s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188001, Requested 17834. Please try again in 42m0.72s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:46:42,237 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:47:42,385 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 187861, Requested 17834. Please try again in 41m0.24s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 187861, Requested 17834. Please try again in 41m0.24s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:47:42,387 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:48:42,527 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 187722, Requested 17834. Please try again in 40m0.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 187722, Requested 17834. Please try again in 40m0.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:48:42,528 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:49:42,669 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 187583, Requested 17834. Please try again in 39m0.144s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 187583, Requested 17834. Please try again in 39m0.144s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:49:42,672 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:50:42,875 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 187444, Requested 17834. Please try again in 38m0.096s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 187444, Requested 17834. Please try again in 38m0.096s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:50:42,878 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:51:43,257 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 187304, Requested 17834. Please try again in 36m59.616s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 187304, Requested 17834. Please try again in 36m59.616s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:51:43,259 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:52:43,404 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 187164, Requested 17834. Please try again in 35m59.136s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 187164, Requested 17834. Please try again in 35m59.136s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:52:43,406 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:53:43,716 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 187025, Requested 17834. Please try again in 34m59.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 187025, Requested 17834. Please try again in 34m59.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:53:43,718 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:54:43,927 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 186886, Requested 17834. Please try again in 33m59.04s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 186886, Requested 17834. Please try again in 33m59.04s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:54:43,930 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:55:44,051 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 186746, Requested 17834. Please try again in 32m58.56s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 186746, Requested 17834. Please try again in 32m58.56s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:55:44,053 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:56:44,248 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 186607, Requested 17834. Please try again in 31m58.512s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 186607, Requested 17834. Please try again in 31m58.512s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:56:44,251 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:57:44,433 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 186468, Requested 17834. Please try again in 30m58.464s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 186468, Requested 17834. Please try again in 30m58.464s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:57:44,436 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:58:44,568 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 186328, Requested 17834. Please try again in 29m57.984s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 186328, Requested 17834. Please try again in 29m57.984s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:58:44,571 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 13:59:44,683 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 186189, Requested 17834. Please try again in 28m57.936s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 186189, Requested 17834. Please try again in 28m57.936s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 13:59:44,685 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:00:44,890 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 186050, Requested 17834. Please try again in 27m57.888s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 186050, Requested 17834. Please try again in 27m57.888s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:00:44,893 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:01:45,041 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 185911, Requested 17834. Please try again in 26m57.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 185911, Requested 17834. Please try again in 26m57.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:01:45,042 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:02:45,311 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 185771, Requested 17834. Please try again in 25m57.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 185771, Requested 17834. Please try again in 25m57.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:02:45,314 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:03:45,523 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 185632, Requested 17834. Please try again in 24m57.312s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 185632, Requested 17834. Please try again in 24m57.312s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:03:45,525 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:04:45,735 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 185493, Requested 17834. Please try again in 23m57.264s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 185493, Requested 17834. Please try again in 23m57.264s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:04:45,737 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:05:45,876 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 185353, Requested 17834. Please try again in 22m56.784s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 185353, Requested 17834. Please try again in 22m56.784s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:05:45,878 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:06:46,055 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 185214, Requested 17834. Please try again in 21m56.736s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 185214, Requested 17834. Please try again in 21m56.736s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:06:46,057 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:07:46,368 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 185074, Requested 17834. Please try again in 20m56.256s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 185074, Requested 17834. Please try again in 20m56.256s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:07:46,370 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:08:46,576 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 184935, Requested 17834. Please try again in 19m56.208s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 184935, Requested 17834. Please try again in 19m56.208s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:08:46,579 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:09:46,791 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 184796, Requested 17834. Please try again in 18m56.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 184796, Requested 17834. Please try again in 18m56.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:09:46,794 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:10:46,934 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 184656, Requested 17834. Please try again in 17m55.679999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 184656, Requested 17834. Please try again in 17m55.679999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:10:46,935 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:11:47,104 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 184517, Requested 17834. Please try again in 16m55.632s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 184517, Requested 17834. Please try again in 16m55.632s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:11:47,105 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:12:47,368 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 184377, Requested 17834. Please try again in 15m55.152s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 184377, Requested 17834. Please try again in 15m55.152s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:12:47,370 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:13:47,526 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 184238, Requested 17834. Please try again in 14m55.103999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 184238, Requested 17834. Please try again in 14m55.103999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:13:47,527 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:14:47,737 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 184099, Requested 17834. Please try again in 13m55.056s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 184099, Requested 17834. Please try again in 13m55.056s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:14:47,741 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:15:47,875 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 183960, Requested 17834. Please try again in 12m55.008s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 183960, Requested 17834. Please try again in 12m55.008s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:15:47,878 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:16:48,158 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 183820, Requested 17834. Please try again in 11m54.528s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 183820, Requested 17834. Please try again in 11m54.528s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:16:48,160 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:17:48,574 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 183680, Requested 17834. Please try again in 10m54.048s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 183680, Requested 17834. Please try again in 10m54.048s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:17:48,577 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:18:48,893 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 183541, Requested 17834. Please try again in 9m54s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 183541, Requested 17834. Please try again in 9m54s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:18:48,895 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:19:49,099 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 183401, Requested 17834. Please try again in 8m53.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 183401, Requested 17834. Please try again in 8m53.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:19:49,101 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:20:49,241 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 183262, Requested 17834. Please try again in 7m53.472s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 183262, Requested 17834. Please try again in 7m53.472s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:20:49,244 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:21:49,418 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 183123, Requested 17834. Please try again in 6m53.424s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 183123, Requested 17834. Please try again in 6m53.424s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:21:49,420 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:22:49,733 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 182983, Requested 17834. Please try again in 5m52.944s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 182983, Requested 17834. Please try again in 5m52.944s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:22:49,735 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:23:49,952 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 182844, Requested 17834. Please try again in 4m52.895999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 182844, Requested 17834. Please try again in 4m52.895999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:23:49,954 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:24:50,154 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 182705, Requested 17834. Please try again in 3m52.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 182705, Requested 17834. Please try again in 3m52.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:24:50,156 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:25:50,364 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 182565, Requested 17834. Please try again in 2m52.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 182565, Requested 17834. Please try again in 2m52.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:25:50,366 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:26:50,473 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 182426, Requested 17834. Please try again in 1m52.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 182426, Requested 17834. Please try again in 1m52.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:26:50,475 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:27:50,787 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 17834, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 17834, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:27:50,789 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=19766 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 17834, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:27:50,790 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 14:27:50,947 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 8727, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 8727, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:27:50,949 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=9280 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 8727, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:27:50,950 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 14:28:22,838 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194388, Requested 12156. Please try again in 47m7.008s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194388, Requested 12156. Please try again in 47m7.008s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:28:22,841 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:29:23,049 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194249, Requested 12156. Please try again in 46m6.96s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194249, Requested 12156. Please try again in 46m6.96s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:29:23,051 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:30:23,260 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194110, Requested 12156. Please try again in 45m6.912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194110, Requested 12156. Please try again in 45m6.912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:30:23,262 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:31:23,487 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193970, Requested 12156. Please try again in 44m6.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193970, Requested 12156. Please try again in 44m6.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:31:23,489 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:32:23,682 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193831, Requested 12156. Please try again in 43m6.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193831, Requested 12156. Please try again in 43m6.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:32:23,684 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:33:24,079 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193691, Requested 12156. Please try again in 42m5.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193691, Requested 12156. Please try again in 42m5.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:33:24,081 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:34:24,207 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193552, Requested 12156. Please try again in 41m5.856s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193552, Requested 12156. Please try again in 41m5.856s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:34:24,210 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:35:24,400 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193412, Requested 12156. Please try again in 40m5.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193412, Requested 12156. Please try again in 40m5.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:35:24,403 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:36:24,629 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193273, Requested 12156. Please try again in 39m5.328s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193273, Requested 12156. Please try again in 39m5.328s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:36:24,632 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:37:24,737 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193134, Requested 12156. Please try again in 38m5.28s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193134, Requested 12156. Please try again in 38m5.28s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:37:24,740 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:38:25,254 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192994, Requested 12156. Please try again in 37m4.799999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192994, Requested 12156. Please try again in 37m4.799999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:38:25,254 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:39:25,363 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192855, Requested 12156. Please try again in 36m4.752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192855, Requested 12156. Please try again in 36m4.752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:39:25,364 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:40:25,474 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192715, Requested 12156. Please try again in 35m4.272s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192715, Requested 12156. Please try again in 35m4.272s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:40:25,476 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:41:25,602 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192576, Requested 12156. Please try again in 34m4.224s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192576, Requested 12156. Please try again in 34m4.224s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:41:25,605 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:42:25,801 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192437, Requested 12156. Please try again in 33m4.176s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192437, Requested 12156. Please try again in 33m4.176s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:42:25,803 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:43:26,214 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192297, Requested 12156. Please try again in 32m3.696s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192297, Requested 12156. Please try again in 32m3.696s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:43:26,216 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:44:26,427 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192158, Requested 12156. Please try again in 31m3.648s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192158, Requested 12156. Please try again in 31m3.648s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:44:26,429 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:45:26,597 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192018, Requested 12156. Please try again in 30m3.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192018, Requested 12156. Please try again in 30m3.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:45:26,599 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:46:26,701 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191879, Requested 12156. Please try again in 29m3.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191879, Requested 12156. Please try again in 29m3.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:46:26,702 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:47:26,860 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191740, Requested 12156. Please try again in 28m3.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191740, Requested 12156. Please try again in 28m3.072s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:47:26,862 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:48:27,276 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191600, Requested 12156. Please try again in 27m2.592s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191600, Requested 12156. Please try again in 27m2.592s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:48:27,278 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:49:27,389 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191461, Requested 12156. Please try again in 26m2.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191461, Requested 12156. Please try again in 26m2.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:49:27,391 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:50:27,504 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191322, Requested 12156. Please try again in 25m2.495999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191322, Requested 12156. Please try again in 25m2.495999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:50:27,506 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:51:27,707 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191183, Requested 12156. Please try again in 24m2.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191183, Requested 12156. Please try again in 24m2.448s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:51:27,709 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:52:27,919 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191043, Requested 12156. Please try again in 23m1.967999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191043, Requested 12156. Please try again in 23m1.967999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:52:27,921 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:53:28,232 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190903, Requested 12156. Please try again in 22m1.488s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190903, Requested 12156. Please try again in 22m1.488s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:53:28,235 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:54:28,445 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190764, Requested 12156. Please try again in 21m1.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190764, Requested 12156. Please try again in 21m1.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:54:28,448 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:55:28,659 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190625, Requested 12156. Please try again in 20m1.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190625, Requested 12156. Please try again in 20m1.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:55:28,661 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:56:28,867 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190485, Requested 12156. Please try again in 19m0.912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190485, Requested 12156. Please try again in 19m0.912s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:56:28,870 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:57:29,079 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190346, Requested 12156. Please try again in 18m0.864s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190346, Requested 12156. Please try again in 18m0.864s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:57:29,081 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:58:29,496 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190206, Requested 12156. Please try again in 17m0.383999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190206, Requested 12156. Please try again in 17m0.383999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:58:29,500 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 14:59:29,708 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190067, Requested 12156. Please try again in 16m0.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 190067, Requested 12156. Please try again in 16m0.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 14:59:29,710 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:00:29,805 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189928, Requested 12156. Please try again in 15m0.288s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189928, Requested 12156. Please try again in 15m0.288s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:00:29,806 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:01:29,903 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189788, Requested 12156. Please try again in 13m59.808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189788, Requested 12156. Please try again in 13m59.808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:01:29,904 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:02:30,034 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189649, Requested 12156. Please try again in 12m59.76s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189649, Requested 12156. Please try again in 12m59.76s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:02:30,036 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:03:30,450 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189510, Requested 12156. Please try again in 11m59.712s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189510, Requested 12156. Please try again in 11m59.712s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:03:30,453 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:04:30,565 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189370, Requested 12156. Please try again in 10m59.232s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189370, Requested 12156. Please try again in 10m59.232s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:04:30,568 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:05:30,768 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189231, Requested 12156. Please try again in 9m59.184s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189231, Requested 12156. Please try again in 9m59.184s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:05:30,769 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:06:30,909 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189092, Requested 12156. Please try again in 8m59.135999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 189092, Requested 12156. Please try again in 8m59.135999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:06:30,911 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:07:31,095 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188952, Requested 12156. Please try again in 7m58.656s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188952, Requested 12156. Please try again in 7m58.656s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:07:31,097 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:08:31,387 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188813, Requested 12156. Please try again in 6m58.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188813, Requested 12156. Please try again in 6m58.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:08:31,390 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:09:31,518 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188674, Requested 12156. Please try again in 5m58.56s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188674, Requested 12156. Please try again in 5m58.56s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:09:31,521 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:10:31,725 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188534, Requested 12156. Please try again in 4m58.08s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188534, Requested 12156. Please try again in 4m58.08s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:10:31,726 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:11:31,934 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188395, Requested 12156. Please try again in 3m58.032s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188395, Requested 12156. Please try again in 3m58.032s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:11:31,934 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:12:32,045 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188256, Requested 12156. Please try again in 2m57.984s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188256, Requested 12156. Please try again in 2m57.984s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:12:32,046 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:13:32,404 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188116, Requested 12156. Please try again in 1m57.504s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 188116, Requested 12156. Please try again in 1m57.504s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:13:32,406 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:15:30,629 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 12156, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 12156, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:15:30,630 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=12945 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 12156, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:15:30,630 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 15:15:31,365 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194055, Requested 9115. Please try again in 22m49.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194055, Requested 9115. Please try again in 22m49.44s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:15:31,368 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:16:31,460 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193916, Requested 9115. Please try again in 21m49.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193916, Requested 9115. Please try again in 21m49.392s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:16:31,461 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:17:31,574 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193777, Requested 9115. Please try again in 20m49.344s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193777, Requested 9115. Please try again in 20m49.344s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:17:31,577 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:18:31,698 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193638, Requested 9115. Please try again in 19m49.296s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193638, Requested 9115. Please try again in 19m49.296s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:18:31,700 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:19:31,917 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193498, Requested 9115. Please try again in 18m48.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193498, Requested 9115. Please try again in 18m48.816s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:19:31,919 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:20:32,027 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193359, Requested 9115. Please try again in 17m48.768s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193359, Requested 9115. Please try again in 17m48.768s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:20:32,030 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:21:32,153 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193220, Requested 9115. Please try again in 16m48.719999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193220, Requested 9115. Please try again in 16m48.719999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:21:32,155 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:22:32,449 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193081, Requested 9115. Please try again in 15m48.672s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193081, Requested 9115. Please try again in 15m48.672s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:22:32,450 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:23:32,544 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192941, Requested 9115. Please try again in 14m48.191999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192941, Requested 9115. Please try again in 14m48.191999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:23:32,547 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:24:32,768 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192802, Requested 9115. Please try again in 13m48.144s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192802, Requested 9115. Please try again in 13m48.144s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:24:32,771 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:25:32,878 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192663, Requested 9115. Please try again in 12m48.096s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192663, Requested 9115. Please try again in 12m48.096s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:25:32,880 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:26:33,064 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192524, Requested 9115. Please try again in 11m48.047999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192524, Requested 9115. Please try again in 11m48.047999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:26:33,067 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:27:33,310 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192384, Requested 9115. Please try again in 10m47.568s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192384, Requested 9115. Please try again in 10m47.568s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:27:33,312 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:28:33,394 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192245, Requested 9115. Please try again in 9m47.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192245, Requested 9115. Please try again in 9m47.52s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:28:33,396 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:29:33,496 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192106, Requested 9115. Please try again in 8m47.472s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192106, Requested 9115. Please try again in 8m47.472s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:29:33,496 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:30:33,653 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191967, Requested 9115. Please try again in 7m47.424s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191967, Requested 9115. Please try again in 7m47.424s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:30:33,656 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:31:33,764 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191828, Requested 9115. Please try again in 6m47.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191828, Requested 9115. Please try again in 6m47.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:31:33,766 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:32:33,967 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191688, Requested 9115. Please try again in 5m46.896s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191688, Requested 9115. Please try again in 5m46.896s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:32:33,970 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:33:34,487 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191549, Requested 9115. Please try again in 4m46.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191549, Requested 9115. Please try again in 4m46.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:33:34,489 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:34:34,802 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191409, Requested 9115. Please try again in 3m46.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191409, Requested 9115. Please try again in 3m46.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:34:34,804 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:35:34,909 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191269, Requested 9115. Please try again in 2m45.888s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191269, Requested 9115. Please try again in 2m45.888s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:35:34,910 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:36:35,052 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191130, Requested 9115. Please try again in 1m45.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191130, Requested 9115. Please try again in 1m45.84s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:36:35,053 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:38:21,518 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9115, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9115, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:38:21,518 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=9445 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9115, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:38:21,518 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 15:38:22,447 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197094, Requested 6131. Please try again in 23m13.2s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197094, Requested 6131. Please try again in 23m13.2s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:38:22,448 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:39:22,652 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196955, Requested 6131. Please try again in 22m13.152s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196955, Requested 6131. Please try again in 22m13.152s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:39:22,653 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:40:22,736 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196816, Requested 6131. Please try again in 21m13.104s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196816, Requested 6131. Please try again in 21m13.104s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:40:22,738 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:41:22,825 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196677, Requested 6131. Please try again in 20m13.056s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196677, Requested 6131. Please try again in 20m13.056s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:41:22,828 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:42:22,934 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196537, Requested 6131. Please try again in 19m12.576s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196537, Requested 6131. Please try again in 19m12.576s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:42:22,934 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:43:23,042 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196398, Requested 6131. Please try again in 18m12.528s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196398, Requested 6131. Please try again in 18m12.528s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:43:23,043 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:44:23,165 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196259, Requested 6131. Please try again in 17m12.48s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196259, Requested 6131. Please try again in 17m12.48s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:44:23,168 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:45:23,268 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196120, Requested 6131. Please try again in 16m12.431999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196120, Requested 6131. Please try again in 16m12.431999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:45:23,269 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:46:23,427 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195981, Requested 6131. Please try again in 15m12.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195981, Requested 6131. Please try again in 15m12.384s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:46:23,429 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:47:23,533 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195842, Requested 6131. Please try again in 14m12.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195842, Requested 6131. Please try again in 14m12.336s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:47:23,535 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:48:23,675 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195702, Requested 6131. Please try again in 13m11.856s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195702, Requested 6131. Please try again in 13m11.856s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:48:23,677 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:49:24,005 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195563, Requested 6131. Please try again in 12m11.808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195563, Requested 6131. Please try again in 12m11.808s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:49:24,007 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:50:24,117 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195424, Requested 6131. Please try again in 11m11.76s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195424, Requested 6131. Please try again in 11m11.76s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:50:24,119 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:51:24,218 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195284, Requested 6131. Please try again in 10m11.28s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195284, Requested 6131. Please try again in 10m11.28s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:51:24,219 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:52:24,312 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195145, Requested 6131. Please try again in 9m11.232s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195145, Requested 6131. Please try again in 9m11.232s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:52:24,313 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:53:24,558 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195006, Requested 6131. Please try again in 8m11.183999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195006, Requested 6131. Please try again in 8m11.183999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:53:24,560 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:54:24,667 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194867, Requested 6131. Please try again in 7m11.135999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194867, Requested 6131. Please try again in 7m11.135999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:54:24,669 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:55:24,779 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194728, Requested 6131. Please try again in 6m11.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194728, Requested 6131. Please try again in 6m11.088s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:55:24,781 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:56:25,022 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194588, Requested 6131. Please try again in 5m10.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194588, Requested 6131. Please try again in 5m10.608s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:56:25,024 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:57:25,111 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194449, Requested 6131. Please try again in 4m10.559999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194449, Requested 6131. Please try again in 4m10.559999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:57:25,114 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:58:25,351 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194310, Requested 6131. Please try again in 3m10.512s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194310, Requested 6131. Please try again in 3m10.512s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:58:25,353 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 15:59:26,837 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194167, Requested 6131. Please try again in 2m8.735999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194167, Requested 6131. Please try again in 2m8.735999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 15:59:26,840 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:00:26,938 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194028, Requested 6131. Please try again in 1m8.688s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194028, Requested 6131. Please try again in 1m8.688s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:00:26,939 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:01:37,242 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 200000, Requested 9176. Please try again in 1h6m4.031999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 200000, Requested 9176. Please try again in 1h6m4.031999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:01:37,245 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:02:37,424 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199861, Requested 9176. Please try again in 1h5m3.984s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199861, Requested 9176. Please try again in 1h5m3.984s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:02:37,427 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:03:37,639 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199721, Requested 9176. Please try again in 1h4m3.504s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199721, Requested 9176. Please try again in 1h4m3.504s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:03:37,642 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:04:37,775 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199582, Requested 9176. Please try again in 1h3m3.456s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199582, Requested 9176. Please try again in 1h3m3.456s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:04:37,777 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:05:37,983 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 9176. Please try again in 1h2m3.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 9176. Please try again in 1h2m3.408s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:05:37,984 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:06:38,095 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199304, Requested 9176. Please try again in 1h1m3.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199304, Requested 9176. Please try again in 1h1m3.36s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:06:38,098 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:07:38,306 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199164, Requested 9176. Please try again in 1h0m2.88s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199164, Requested 9176. Please try again in 1h0m2.88s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:07:38,308 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:08:38,622 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199025, Requested 9176. Please try again in 59m2.832s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199025, Requested 9176. Please try again in 59m2.832s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:08:38,624 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:09:38,838 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198885, Requested 9176. Please try again in 58m2.352s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198885, Requested 9176. Please try again in 58m2.352s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:09:38,839 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:10:39,049 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198746, Requested 9176. Please try again in 57m2.304s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198746, Requested 9176. Please try again in 57m2.304s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:10:39,051 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:11:39,262 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198607, Requested 9176. Please try again in 56m2.256s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198607, Requested 9176. Please try again in 56m2.256s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:11:39,265 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:12:39,410 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198467, Requested 9176. Please try again in 55m1.776s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198467, Requested 9176. Please try again in 55m1.776s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:12:39,412 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:13:39,690 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198328, Requested 9176. Please try again in 54m1.727999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198328, Requested 9176. Please try again in 54m1.727999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:13:39,692 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:14:39,893 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198188, Requested 9176. Please try again in 53m1.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198188, Requested 9176. Please try again in 53m1.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:14:39,895 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:15:40,106 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198049, Requested 9176. Please try again in 52m1.2s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 198049, Requested 9176. Please try again in 52m1.2s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:15:40,108 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:16:40,419 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197909, Requested 9176. Please try again in 51m0.72s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197909, Requested 9176. Please try again in 51m0.72s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:16:40,422 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:17:40,631 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197770, Requested 9176. Please try again in 50m0.671999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197770, Requested 9176. Please try again in 50m0.671999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:17:40,633 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:18:40,950 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197630, Requested 9176. Please try again in 49m0.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197630, Requested 9176. Please try again in 49m0.192s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:18:40,952 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:19:41,157 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197491, Requested 9176. Please try again in 48m0.144s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197491, Requested 9176. Please try again in 48m0.144s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:19:41,159 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:20:41,371 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197352, Requested 9176. Please try again in 47m0.096s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197352, Requested 9176. Please try again in 47m0.096s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:20:41,373 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:21:41,583 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197212, Requested 9176. Please try again in 45m59.616s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197212, Requested 9176. Please try again in 45m59.616s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:21:41,585 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:22:41,793 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197073, Requested 9176. Please try again in 44m59.568s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 197073, Requested 9176. Please try again in 44m59.568s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:22:41,795 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:23:42,106 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196933, Requested 9176. Please try again in 43m59.087999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196933, Requested 9176. Please try again in 43m59.087999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:23:42,108 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:24:42,194 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196794, Requested 9176. Please try again in 42m59.04s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196794, Requested 9176. Please try again in 42m59.04s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:24:42,196 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:25:42,288 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196655, Requested 9176. Please try again in 41m58.992s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196655, Requested 9176. Please try again in 41m58.992s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:25:42,289 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:26:42,417 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196516, Requested 9176. Please try again in 40m58.944s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196516, Requested 9176. Please try again in 40m58.944s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:26:42,420 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:27:42,645 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196377, Requested 9176. Please try again in 39m58.896s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196377, Requested 9176. Please try again in 39m58.896s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:27:42,648 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:28:42,822 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196237, Requested 9176. Please try again in 38m58.415999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196237, Requested 9176. Please try again in 38m58.415999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:28:42,825 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:29:42,916 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196098, Requested 9176. Please try again in 37m58.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 196098, Requested 9176. Please try again in 37m58.368s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:29:42,917 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:30:43,068 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195959, Requested 9176. Please try again in 36m58.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195959, Requested 9176. Please try again in 36m58.32s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:30:43,070 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:31:43,179 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195820, Requested 9176. Please try again in 35m58.272s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195820, Requested 9176. Please try again in 35m58.272s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:31:43,181 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:32:43,325 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195680, Requested 9176. Please try again in 34m57.792s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195680, Requested 9176. Please try again in 34m57.792s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:32:43,327 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:33:43,594 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195541, Requested 9176. Please try again in 33m57.744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195541, Requested 9176. Please try again in 33m57.744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:33:43,597 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:34:43,715 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195402, Requested 9176. Please try again in 32m57.696s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195402, Requested 9176. Please try again in 32m57.696s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:34:43,718 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:35:43,916 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195262, Requested 9176. Please try again in 31m57.216s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195262, Requested 9176. Please try again in 31m57.216s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:35:43,919 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:36:44,102 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195123, Requested 9176. Please try again in 30m57.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195123, Requested 9176. Please try again in 30m57.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:36:44,103 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:37:44,282 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194984, Requested 9176. Please try again in 29m57.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194984, Requested 9176. Please try again in 29m57.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:37:44,285 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:38:44,649 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194844, Requested 9176. Please try again in 28m56.639999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194844, Requested 9176. Please try again in 28m56.639999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:38:44,651 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:39:44,964 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194704, Requested 9176. Please try again in 27m56.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194704, Requested 9176. Please try again in 27m56.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:39:44,967 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:40:45,175 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194565, Requested 9176. Please try again in 26m56.111999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194565, Requested 9176. Please try again in 26m56.111999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:40:45,177 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:41:45,388 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194426, Requested 9176. Please try again in 25m56.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194426, Requested 9176. Please try again in 25m56.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:41:45,391 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:42:45,700 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194286, Requested 9176. Please try again in 24m55.583999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194286, Requested 9176. Please try again in 24m55.583999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:42:45,703 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:43:45,889 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194147, Requested 9176. Please try again in 23m55.536s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194147, Requested 9176. Please try again in 23m55.536s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:43:45,890 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:44:46,226 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194007, Requested 9176. Please try again in 22m55.055999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194007, Requested 9176. Please try again in 22m55.055999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:44:46,229 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:45:46,418 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193868, Requested 9176. Please try again in 21m55.008s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193868, Requested 9176. Please try again in 21m55.008s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:45:46,421 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:46:46,565 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193728, Requested 9176. Please try again in 20m54.528s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193728, Requested 9176. Please try again in 20m54.528s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:46:46,568 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:47:46,739 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193589, Requested 9176. Please try again in 19m54.48s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193589, Requested 9176. Please try again in 19m54.48s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:47:46,739 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:48:46,967 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193450, Requested 9176. Please try again in 18m54.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193450, Requested 9176. Please try again in 18m54.432s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:48:46,969 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:49:47,179 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193310, Requested 9176. Please try again in 17m53.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193310, Requested 9176. Please try again in 17m53.952s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:49:47,181 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:50:47,305 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193171, Requested 9176. Please try again in 16m53.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193171, Requested 9176. Please try again in 16m53.904s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:50:47,307 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:51:47,408 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193032, Requested 9176. Please try again in 15m53.856s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 193032, Requested 9176. Please try again in 15m53.856s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:51:47,411 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:52:47,708 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192892, Requested 9176. Please try again in 14m53.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192892, Requested 9176. Please try again in 14m53.376s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:52:47,709 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:53:48,004 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192753, Requested 9176. Please try again in 13m53.328s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192753, Requested 9176. Please try again in 13m53.328s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:53:48,007 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:54:48,407 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192613, Requested 9176. Please try again in 12m52.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192613, Requested 9176. Please try again in 12m52.848s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:54:48,410 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:55:48,550 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192474, Requested 9176. Please try again in 11m52.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192474, Requested 9176. Please try again in 11m52.8s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:55:48,553 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:56:48,696 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192335, Requested 9176. Please try again in 10m52.752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192335, Requested 9176. Please try again in 10m52.752s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:56:48,698 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:57:48,871 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192195, Requested 9176. Please try again in 9m52.272s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192195, Requested 9176. Please try again in 9m52.272s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:57:48,873 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:58:49,173 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192056, Requested 9176. Please try again in 8m52.223999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 192056, Requested 9176. Please try again in 8m52.223999999s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:58:49,176 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 16:59:49,502 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191916, Requested 9176. Please try again in 7m51.744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191916, Requested 9176. Please try again in 7m51.744s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 16:59:49,505 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:00:49,632 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191777, Requested 9176. Please try again in 6m51.696s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191777, Requested 9176. Please try again in 6m51.696s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:00:49,635 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:01:49,920 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191637, Requested 9176. Please try again in 5m51.216s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191637, Requested 9176. Please try again in 5m51.216s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:01:49,921 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:02:50,267 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191498, Requested 9176. Please try again in 4m51.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191498, Requested 9176. Please try again in 4m51.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:02:50,270 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:03:50,421 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191358, Requested 9176. Please try again in 3m50.688s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191358, Requested 9176. Please try again in 3m50.688s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:03:50,422 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:04:50,765 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191219, Requested 9176. Please try again in 2m50.64s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191219, Requested 9176. Please try again in 2m50.64s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:04:50,766 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:05:50,975 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191079, Requested 9176. Please try again in 1m50.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 191079, Requested 9176. Please try again in 1m50.16s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:05:50,978 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:07:42,385 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9176, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.APIStatusError: Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9176, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:07:42,388 WARNING SIZE/CONTEXT error detected for provider=groq model=openai/gpt-oss-120b: estimated_request_tokens=13927 error=Error code: 413 - {'error': {'message': 'Request too large for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per minute (TPM): Limit 8000, Requested 9176, please reduce your message size and try again. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:07:42,388 INFO Splitting oversized request into 2 chats for provider=groq model=openai/gpt-oss-120b
2025-12-09 17:07:43,570 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195180, Requested 5727. Please try again in 6m31.824s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195180, Requested 5727. Please try again in 6m31.824s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:07:43,572 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:08:43,716 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195041, Requested 5727. Please try again in 5m31.776s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 195041, Requested 5727. Please try again in 5m31.776s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:08:43,718 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:09:43,937 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194902, Requested 5727. Please try again in 4m31.728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194902, Requested 5727. Please try again in 4m31.728s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:09:43,939 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:10:44,151 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194762, Requested 5727. Please try again in 3m31.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194762, Requested 5727. Please try again in 3m31.248s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:10:44,152 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:11:44,258 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194623, Requested 5727. Please try again in 2m31.2s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194623, Requested 5727. Please try again in 2m31.2s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:11:44,260 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:12:44,366 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194484, Requested 5727. Please try again in 1m31.152s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 194484, Requested 5727. Please try again in 1m31.152s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:12:44,369 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:14:17,857 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 200000, Requested 10924. Please try again in 1h18m39.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 200000, Requested 10924. Please try again in 1h18m39.168s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:14:17,859 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:15:18,034 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199861, Requested 10924. Please try again in 1h17m39.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199861, Requested 10924. Please try again in 1h17m39.12s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:15:18,036 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:16:18,172 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199721, Requested 10924. Please try again in 1h16m38.64s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199721, Requested 10924. Please try again in 1h16m38.64s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:16:18,173 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:17:18,378 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199582, Requested 10924. Please try again in 1h15m38.592s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199582, Requested 10924. Please try again in 1h15m38.592s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:17:18,381 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:18:18,589 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 10924. Please try again in 1h14m38.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199443, Requested 10924. Please try again in 1h14m38.544s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:18:18,591 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
2025-12-09 17:19:18,680 ERROR send_chat error provider=groq model=openai/gpt-oss-120b: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199303, Requested 10924. Please try again in 1h13m38.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
Traceback (most recent call last):
  File "/home/vro5/Coding/AgenticSolvers/test/benchmark_chat.py", line 201, in send_chat
    return query_func(joined, model_name=model_id)
           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/utils.py", line 124, in query_groq
    chat_completion = client.chat.completions.create(
                      ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/resources/chat/completions.py", line 456, in create
    return self._post(
           ^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1242, in post
    return cast(ResponseT, self.request(cast_to, opts, stream=stream, stream_cls=stream_cls))
                           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^
  File "/home/vro5/Coding/AgenticSolvers/.venv/lib/python3.12/site-packages/groq/_base_client.py", line 1044, in request
    raise self._make_status_error_from_response(err.response) from None
groq.RateLimitError: Error code: 429 - {'error': {'message': 'Rate limit reached for model `openai/gpt-oss-120b` in organization `org_01k9qqesvte4d9h5jnhmzvbmy4` service tier `on_demand` on tokens per day (TPD): Limit 200000, Used 199303, Requested 10924. Please try again in 1h13m38.064s. Need more tokens? Upgrade to Dev Tier today at https://console.groq.com/settings/billing', 'type': 'tokens', 'code': 'rate_limit_exceeded'}}
2025-12-09 17:19:18,681 INFO Received rate-limit/429 for provider=groq model=openai/gpt-oss-120b; sleeping 60s before retry
